{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna study\n",
    "\n",
    "> Combine it with papermill and wandb for seamless hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/pip-global/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import optuna\n",
    "from tsai.optuna import *\n",
    "from tsai.basics import load_object\n",
    "import papermill as pm\n",
    "from tsai.optuna import run_optuna_study\n",
    "from fastcore.basics import *\n",
    "from optuna.distributions import *\n",
    "from optuna.samplers import TPESampler\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{ 'extra_params': {'bs': 32, 'is_optuna_study': True, 'n_epoch': 100},\n",
       "  'n_trials': 50,\n",
       "  'search_space': { 'arch.attn_dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.1),\n",
       "                    'arch.d_ff': IntUniformDistribution(high=512, low=32, step=32),\n",
       "                    'arch.d_model': IntUniformDistribution(high=512, low=32, step=32),\n",
       "                    'arch.decomposition': CategoricalDistribution(choices=(True, False)),\n",
       "                    'arch.dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.1),\n",
       "                    'arch.individual': CategoricalDistribution(choices=(True, False)),\n",
       "                    'arch.n_heads': CategoricalDistribution(choices=(2, 4, 8, 16, 32)),\n",
       "                    'arch.n_layers': IntUniformDistribution(high=6, low=1, step=1),\n",
       "                    'deltaHL': FloatDistribution(high=15.0, log=False, low=1.0, step=1.0),\n",
       "                    'init_weights': CategoricalDistribution(choices=(True, False)),\n",
       "                    'lookback': CategoricalDistribution(choices=(18, 24, 36, 128, 192))},\n",
       "  'study_name': 'general_study_extended',\n",
       "  'study_type': 'bayesian',\n",
       "  'train_nb': '/workspaces/sw-driver-forecaster/dev_nbs/solfsmy_train.ipynb',\n",
       "  'use_wandb': True,\n",
       "  'wandb_mode': 'offline'}\n",
       "```"
      ],
      "text/plain": [
       "{'study_name': 'general_study_extended',\n",
       " 'study_type': 'bayesian',\n",
       " 'n_trials': 50,\n",
       " 'train_nb': '/workspaces/sw-driver-forecaster/dev_nbs/solfsmy_train.ipynb',\n",
       " 'search_space': {'arch.attn_dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.1),\n",
       "  'arch.d_model': IntUniformDistribution(high=512, low=32, step=32),\n",
       "  'arch.d_ff': IntUniformDistribution(high=512, low=32, step=32),\n",
       "  'arch.decomposition': CategoricalDistribution(choices=(True, False)),\n",
       "  'arch.dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.1),\n",
       "  'arch.individual': CategoricalDistribution(choices=(True, False)),\n",
       "  'arch.n_layers': IntUniformDistribution(high=6, low=1, step=1),\n",
       "  'arch.n_heads': CategoricalDistribution(choices=(2, 4, 8, 16, 32)),\n",
       "  'init_weights': CategoricalDistribution(choices=(True, False)),\n",
       "  'lookback': CategoricalDistribution(choices=(18, 24, 36, 128, 192)),\n",
       "  'deltaHL': FloatDistribution(high=15.0, log=False, low=1.0, step=1.0)},\n",
       " 'extra_params': {'n_epoch': 100, 'bs': 32, 'is_optuna_study': True},\n",
       " 'use_wandb': True,\n",
       " 'wandb_mode': 'offline'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AttrDict(\n",
    "    study_name = 'general_study_extended', # name of the Optuna study\n",
    "    study_type = 'bayesian', # 'bayesian' or 'gridsearch' or 'random'\n",
    "    n_trials = 50, # number of trials\n",
    "    train_nb = f'{os.getcwd()}/solfsmy_train.ipynb', # path to the notebook to be executed\n",
    "    search_space = {\n",
    "        \"arch.attn_dropout\": DiscreteUniformDistribution(0.0, 0.5, 0.1),\n",
    "        \"arch.d_model\": IntUniformDistribution(32, 512, 32),\n",
    "        \"arch.d_ff\": IntUniformDistribution(32, 512, 32),\n",
    "        \"arch.decomposition\": CategoricalDistribution([True, False]),\n",
    "        \"arch.dropout\": DiscreteUniformDistribution(0.0, 0.5, 0.1), \n",
    "        \"arch.individual\": CategoricalDistribution([True, False]),\n",
    "        \"arch.n_layers\": IntUniformDistribution(1, 6, 1),\n",
    "        \"arch.n_heads\": CategoricalDistribution([2, 4, 8, 16, 32]),\n",
    "        \"init_weights\": CategoricalDistribution([True, False]), # true = kaiming\n",
    "        \"lookback\": CategoricalDistribution([18, 24, 36, 128, 192]),\n",
    "        \"deltaHL\": FloatDistribution(1., 15., step=1.),\n",
    "    },\n",
    "    # Add extra parameters that are fixed, but not part of the search space\n",
    "    extra_params = {\n",
    "        \"n_epoch\": 100,\n",
    "        \"bs\": 32,\n",
    "        \"is_optuna_study\": True\n",
    "    },\n",
    "    use_wandb = True,\n",
    "    wandb_mode = 'offline'\n",
    ")\n",
    "\n",
    "%store -d best_valid_loss                                             \n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_objective(train_nb, search_space, extra_params=None, use_wandb=False):\n",
    "    \"\"\"\n",
    "        Create objective function to be minimized by Optuna.\n",
    "        Inputs:\n",
    "            trial: Optuna trial object\n",
    "            train_nb: path to the training notebook\n",
    "            search_vars: keys of the search space to be used\n",
    "            wandb_group: name of the wandb group to be used\n",
    "        Output:\n",
    "            valid_loss: validation loss\n",
    "    \"\"\"\n",
    "    def objective(trial:optuna.Trial):\n",
    "        # Define the parameters to be passed to the training notebook through papermill\n",
    "        pm_parameters = {}\n",
    "        for k,v in search_space.items():\n",
    "            pm_parameters['config.' + k] = trial._suggest(k, v)\n",
    "\n",
    "        # Add the extra parameters to the dictionary. The key of every parameter \n",
    "        # must be 'config.<param_name>'\n",
    "        if extra_params is not None:\n",
    "            for k,v in extra_params.items():\n",
    "                pm_parameters['config.' + k] = v\n",
    "                \n",
    "        # If using wandb, enable that in the training runs, all of them gathered\n",
    "        # into a group (NOTE: The train nb must have and use these config arguments)\n",
    "        if use_wandb:\n",
    "            pm_parameters['config.use_wandb'] = True\n",
    "            pm_parameters['config.wandb_group'] = config.study_name + '_runs'\n",
    "\n",
    "        # Call the training notebook using papermill (don't print the output)\n",
    "        stdout_file = open('tmp/pm_stdout.txt', 'w')\n",
    "        stderr_file = open('tmp/pm_stderr.txt', 'w')\n",
    "\n",
    "        pm.execute_notebook(\n",
    "            train_nb,\n",
    "            './tmp/pm_output.ipynb',\n",
    "            parameters = pm_parameters,\n",
    "            stdout_file = stdout_file,\n",
    "            stderr_file = stderr_file\n",
    "        )\n",
    "\n",
    "        # Close the output files\n",
    "        stdout_file.close()\n",
    "        stderr_file.close()\n",
    "\n",
    "        # Get the output value of interest from the source notebook\n",
    "        loss = None\n",
    "        %store -r valid_loss\n",
    "        return valid_loss\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-22 07:37:35,427] A new study created in memory with name: general_study_extended\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passed unknown parameter: config.arch.attn_dropout\n",
      "Passed unknown parameter: config.arch.d_model\n",
      "Passed unknown parameter: config.arch.d_ff\n",
      "Passed unknown parameter: config.arch.decomposition\n",
      "Passed unknown parameter: config.arch.dropout\n",
      "Passed unknown parameter: config.arch.individual\n",
      "Passed unknown parameter: config.arch.n_layers\n",
      "Passed unknown parameter: config.arch.n_heads\n",
      "Passed unknown parameter: config.init_weights\n",
      "Passed unknown parameter: config.lookback\n",
      "Passed unknown parameter: config.deltaHL\n",
      "Passed unknown parameter: config.n_epoch\n",
      "Passed unknown parameter: config.bs\n",
      "Passed unknown parameter: config.is_optuna_study\n",
      "Passed unknown parameter: config.use_wandb\n",
      "Passed unknown parameter: config.wandb_group\n"
     ]
    }
   ],
   "source": [
    "obj = create_objective(config.train_nb, config.search_space, \n",
    "                       extra_params=config.extra_params, use_wandb=True)\n",
    "study = run_optuna_study(obj, study_type='bayesian', direction='minimize', path='./tmp',\n",
    "                 study_name=config.study_name, n_trials=config.n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(config=config, mode=config.wandb_mode, \n",
    "                 job_type='optuna-study') if config.use_wandb else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run is not None:\n",
    "    run.log(dict(study.best_params, **{'best_value': study.best_value, \n",
    "                                       'best_trial_number': study.best_trial.number}))\n",
    "    run.log_artifact(f'./tmp/{config.study_name}.pkl', type='optuna_study')\n",
    "    run.log({\n",
    "        'contour': optuna.visualization.plot_contour(study),\n",
    "        'edf': optuna.visualization.plot_edf(study),\n",
    "        'intermediate_values': optuna.visualization.plot_intermediate_values(study),\n",
    "        'optimization_history': optuna.visualization.plot_optimization_history(study),\n",
    "        'parallel_coordinate' : optuna.visualization.plot_parallel_coordinate(study),\n",
    "        'param_importances': optuna.visualization.plot_param_importances(study),\n",
    "        'slice': optuna.visualization.plot_slice(study)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run is not None:\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
