{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of SOLFSMY\n",
    "\n",
    "> With respect to the benchmark by Licata et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from swdf.benchmark import *\n",
    "from tsai.basics import *\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from swdf.utils import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ARTIFACT_DOWNLOAD_PATH = Path(os.environ[\"WANDB_DIR\"])/\"wandb/artifacts/solfsmy_eval_tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "config = yaml2dict('config/solfsmy.yaml')\n",
    "config = config.eval\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# learn.path = Path(path)\n",
    "# learn.model_dir = Path()\n",
    "if config.learner_artifact is None:\n",
    "    learner_path = 'tmp'\n",
    "else:\n",
    "    learner_path = wandb_api.artifact(config.learner_artifact).download(root=ARTIFACT_DOWNLOAD_PATH)\n",
    "learn = load_learner_all(learner_path, model_fname = 'model', \n",
    "                         verbose=True, \n",
    "                         device=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the test loss\n",
    "print(f'Test loss: {learn.validate(ds_idx=2)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds, y_test = learn.get_preds(ds_idx = 2, with_targs=True)\n",
    "y_test_preds = to_np(y_test_preds)\n",
    "y_test = to_np(y_test)\n",
    "print(f\"y_test_preds.shape: {y_test_preds.shape}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = y_test.shape[-1]\n",
    "data_columns_fcst = ['F10', 'S10', 'M10', 'Y10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation is done for each variable separately, for each solar activity \n",
    "level (low, moderate, elevated and high), as in the paper by Licata et al. (2020)\n",
    "Therefore, the test set has to be split into 4 different sets, one for each solar activity level. The thresholds for each solar activity level are the same as in the paper by Licata et al. (2020)\n",
    "\n",
    "The thresholds are:\n",
    "- F10: 75, 150, 190\n",
    "- S10: 65, 150, 215\n",
    "- M10: 72, 144, 167\n",
    "- Y10: 81, 148, 165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def get_idxs_per_solar_activity_level(data, thresholds):\n",
    "    # function that splits the data of a variable into 4 different sets, \n",
    "    # one for each solar activity level. The data comes as a numpy array with \n",
    "    # shape (samples, steps), and the split is done along the samples axis. \n",
    "    # The decision is made based on the first column of each sample. The function \n",
    "    # returns a list of 4 numpy arrays, one for each solar activity level. \n",
    "    # But it does not return the values, it returns the indices of the\n",
    "    # samples that belong to each solar activity level.\n",
    "    idxs_per_solar_activity_level = []\n",
    "    for i in range(len(thresholds) + 1):\n",
    "        if i == 0:\n",
    "            idxs = np.where(data[:, 0] <= thresholds[i])[0]\n",
    "        elif i == len(thresholds):\n",
    "            idxs = np.where(data[:, 0] > thresholds[i-1])[0]\n",
    "        else:\n",
    "            idxs = np.where((data[:, 0] > thresholds[i-1]) & (data[:, 0] <= thresholds[i]))[0]\n",
    "        idxs_per_solar_activity_level.append(idxs)\n",
    "    return idxs_per_solar_activity_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for each variable, using y_test\n",
    "thresholds = {'F10': [75, 150, 190], \n",
    "              'S10': [65, 150, 215], \n",
    "              'M10': [72, 144, 167], \n",
    "              'Y10': [81, 148, 165]}\n",
    "\n",
    "y_test_split_idxs = {}\n",
    "for i, var in enumerate(data_columns_fcst):\n",
    "    y_test_split_idxs[var] = get_idxs_per_solar_activity_level(y_test[:, i, :], \n",
    "                                                               thresholds[var])\n",
    "# Check the shape of each variable\n",
    "for var in data_columns_fcst:\n",
    "    print(f\"{var}: {[y_test_split_idxs[var][i].shape for i in range(4)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now split y_test and y_test_preds with the idxs we got, using numpy.take\n",
    "y_test_split = {}\n",
    "y_test_preds_split = {}\n",
    "for var in data_columns_fcst:\n",
    "    y_test_split[var] = [y_test[:, i, :].take(y_test_split_idxs[var][i], axis=0) for i in range(4)]\n",
    "    y_test_preds_split[var] = [y_test_preds[:, i, :].take(y_test_split_idxs[var][i], axis=0) for i in range(4)]\n",
    "\n",
    "# Check the shape of each variable in y_test_split\n",
    "for var in data_columns_fcst:\n",
    "    print(f\"y_test-{var}: {[y_test_split[var][i].shape for i in range(4)]}\")\n",
    "    print(f\"y_test_preds-{var}: {[y_test_preds_split[var][i].shape for i in range(4)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Test with random data (torch)\n",
    "foo = torch.rand(10, 3)\n",
    "bar = torch.rand(10, 3)\n",
    "print(forecast_error(foo, bar, 1))\n",
    "print(percent_forecast_error(foo, bar, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table (dataframe) with the mean forecast error for each variable (F10, S10, M10, Y10), \n",
    "# each solar activity level and each horizon (1..horizon)\n",
    "data = []\n",
    "sals = ['low', 'moderate', 'elevated', 'high']\n",
    "for var_idx, var in enumerate(data_columns_fcst):\n",
    "    for sal_idx,sal in enumerate(sals):\n",
    "        for h in range(1, horizon+1):\n",
    "            fe_sfu = forecast_error(y_test_split[var][sal_idx], \n",
    "                                y_test_preds_split[var][sal_idx], h)\n",
    "            fe_percent = percent_forecast_error(y_test_split[var][sal_idx],\n",
    "                                            y_test_preds_split[var][sal_idx], h)\n",
    "            n_samples = y_test_split[var][sal_idx].shape[0]\n",
    "            data.append([var, sal, h, np.mean(fe_sfu), np.std(fe_sfu), \n",
    "                        np.mean(fe_percent), np.std(fe_percent), n_samples])\n",
    "df_results = pd.DataFrame(data, columns=['variable', 'condition', 'horizon', \n",
    "                                         'mean_sfu', 'std_sfu', 'mean_percent', \n",
    "                                         'std_percent', 'n_samples'])\n",
    "df_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the table into one dataframe for each variable, and print it in a way\n",
    "# that has the same format as the table in the paper, that is:\n",
    "# Columns: | Condition | Statistics | 1 Day | 2 Days | 3 Days | ... | {{horizon}} Days,\n",
    "# where condition is the variable and the solar activity level, and statistics \n",
    "# is the mean (column mean_fe) and the standard deviation (std_fe) of the forecast error.\n",
    "for i, var in enumerate(data_columns_fcst):\n",
    "    df_var = df_results[df_results['variable'] == var]\n",
    "\n",
    "    df_var = df_var.melt(id_vars=['condition', 'horizon'], \n",
    "                         value_vars=['mean_sfu', 'std_sfu'], \n",
    "                         var_name='Statistic')\n",
    "    # Sort the values of the column condition so that the order is \n",
    "    # low, moderate, elevated, high\n",
    "    df_var['condition'] = pd.Categorical(df_var['condition'], \n",
    "                                      categories=['low', 'moderate', 'elevated', 'high'], \n",
    "                                      ordered=True)\n",
    "    df_var = df_var.pivot_table(index=['condition', 'Statistic'], \n",
    "                          columns='horizon', \n",
    "                          values='value')\n",
    "    # pretty print, and separate with a blank line\n",
    "    print(f'Distribution Statistics {var} Error Distribution \\n{df_var.to_string()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df_results into long format\n",
    "df_results_lf = df_results.melt(id_vars=['variable', 'condition', 'horizon'],\n",
    "                                value_vars=['mean_sfu', 'std_sfu', 'mean_percent', 'std_percent'],\n",
    "                                var_name='statistic')\n",
    "\n",
    "# Filter out the percent statistics\n",
    "df_results_lf = df_results_lf[df_results_lf['statistic'].str.contains('percent') == False]\n",
    "\n",
    "# Rename the Statistic 'mean_sfu' to just 'mean' and 'std_sfu' to 'std'\n",
    "df_results_lf['statistic'] = df_results_lf['statistic'].str.replace('_sfu', '')\n",
    "\n",
    "df_results_lf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare these results with the results in the paper. The results in the paper\n",
    "# can be found in the data folder as a csv\n",
    "df_results_paper = pd.read_csv('../data/paper_results.csv')\n",
    "\n",
    "# Filter out the rows with Statistics = 'EBM'\n",
    "df_results_paper = df_results_paper[df_results_paper['statistic'] != 'EBM']\n",
    "\n",
    "# Rename the values of the column condition to the ones of the sals variable\n",
    "df_results_paper['condition'] = df_results_paper['condition'].str.replace('Low solar', 'low')\n",
    "df_results_paper['condition'] = df_results_paper['condition'].str.replace('Moderate solar', 'moderate')\n",
    "df_results_paper['condition'] = df_results_paper['condition'].str.replace('Elevated solar', 'elevated')\n",
    "df_results_paper['condition'] = df_results_paper['condition'].str.replace('High solar', 'high')\n",
    "\n",
    "df_results_paper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df_results_paper into long format\n",
    "df_results_paper_lf = df_results_paper.melt(id_vars=['variable', 'condition', 'statistic'],\n",
    "                                            value_vars=[f'{i} Days' for i in range(1, horizon+1)],\n",
    "                                            var_name='horizon', value_name='value')\n",
    "\n",
    "# Convert the value sof the horizon column to int\n",
    "df_results_paper_lf['horizon'] = df_results_paper_lf['horizon'].str.replace(' Days', '').astype(int)\n",
    "df_results_paper_lf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two dataframes (df_results_ours and df_results_paper) on the columns \n",
    "# variable, condition and Statistic\n",
    "df_results_joined = df_results_lf.merge(df_results_paper_lf, how='left', \n",
    "                                            on=['variable', 'condition', 'statistic', 'horizon'],\n",
    "                                            suffixes=('_ours', '_paper'))\n",
    "len(df_results_lf), len(df_results_paper_lf), len(df_results_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the table so that it compares the results of our model with the results \n",
    "# of the paper. Create one table for each variable, and print it in a way that has\n",
    "# the following format:\n",
    "# Columns: | Condition | 1 Day | 2 Days | 3 Days | ... | {{horizon}} Days\n",
    "# where condition is the variable and the solar activity level, and the values\n",
    "# for each horizon are the concatenation of the mean and the standard deviation\n",
    "# (with the symbol ±) of the forecast error of our model and the paper.\n",
    "\n",
    "# Spread the values of the column statistic.\n",
    "foo = df_results_joined.pivot_table(index=['variable', 'condition', 'horizon'],\n",
    "                                                    columns='statistic',\n",
    "                                                    values=['value_ours', 'value_paper'])\n",
    "\n",
    "\n",
    "# Mutate the columns mean and std so that they are bolded in case they are the the \n",
    "# higher that the same statistic in the paper, or vice versa. The mutated column\n",
    "# will not replace the original column, but will be added as a new column. Don't\n",
    "# use the apply function\n",
    "foo.loc[:, ('value_ours', 'mean_str')] = np.where(np.abs(foo['value_ours']['mean']) < np.abs(foo['value_paper']['mean']), \n",
    "                    '\\\\textbf{' + foo['value_ours']['mean'].astype(str) + '}',\n",
    "                    foo['value_ours']['mean'].astype(str))\n",
    "foo.loc[:, ('value_ours', 'std_str')] = np.where(np.abs(foo['value_ours']['std']) < np.abs(foo['value_paper']['std']),\n",
    "                    '\\\\textbf{' + foo['value_ours']['std'].astype(str) + '}',\n",
    "                    foo['value_ours']['std'].astype(str))\n",
    "foo.loc[:, ('value_paper', 'mean_str')] = np.where(np.abs(foo['value_paper']['mean']) < np.abs(foo['value_ours']['mean']),\n",
    "                    '\\\\textbf{' + foo['value_paper']['mean'].astype(str) + '}',\n",
    "                    foo['value_paper']['mean'].astype(str))\n",
    "foo.loc[:, ('value_paper', 'std_str')] = np.where(np.abs(foo['value_paper']['std']) < np.abs(foo['value_ours']['std']),\n",
    "                    '\\\\textbf{' + foo['value_paper']['std'].astype(str) + '}',\n",
    "                    foo['value_paper']['std'].astype(str))\n",
    "\n",
    "# Drop the columns mean and std but not the mutated columns mean_str and std_str\n",
    "foo = foo.drop(columns=[('value_ours', 'mean'), ('value_ours', 'std'),\n",
    "                        ('value_paper', 'mean'), ('value_paper', 'std')])\n",
    "\n",
    "# Unite the mean and the standard deviation into a single column for both our\n",
    "# model and the paper, and drop the mean_str and std_str columns\n",
    "foo.loc[:, ('value_ours', 'mean ± std')] = foo['value_ours']['mean_str'] + ' ± ' + foo['value_ours']['std_str']\n",
    "foo.loc[:, ('value_paper', 'mean ± std')] = foo['value_paper']['mean_str'] + ' ± ' + foo['value_paper']['std_str']\n",
    "foo = foo.drop(columns=[('value_ours', 'mean_str'), ('value_ours', 'std_str'),\n",
    "                        ('value_paper', 'mean_str'), ('value_paper', 'std_str')])\n",
    "\n",
    "# Drop the level 0 of the columns, and rename the columns\n",
    "foo.columns = foo.columns.droplevel(0)\n",
    "foo.columns = ['NN', 'benchmark']\n",
    "\n",
    "# Reset the index\n",
    "foo = foo.reset_index()\n",
    "\n",
    "# Sort the values of the column condition so that the order is \n",
    "# low, moderate, elevated, high\n",
    "foo['condition'] = pd.Categorical(foo['condition'], categories=['low', 'moderate', 'elevated', 'high'], ordered=True)\n",
    "foo = foo.sort_values(by=['variable', 'condition'])\n",
    "\n",
    "\n",
    "# Print as a Latex table, one table for each variable\n",
    "for variable in data_columns_fcst:\n",
    "    print(foo[foo['variable'] == variable].drop(columns='variable').to_latex(\n",
    "        index=False, \n",
    "        escape=False,\n",
    "        column_format='|l|' + '|c|' * horizon,\n",
    "        caption=f'Comparison of the results of the paper with the results of our model for the variable {variable}',\n",
    "        label=f'tab:comparison_{variable}'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "plot_solar_algorithm_performance(df_results, 'F10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "plot_solar_algorithm_performance(df_results, 'S10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "plot_solar_algorithm_performance(df_results, 'M10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "plot_solar_algorithm_performance(df_results, 'Y10')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
