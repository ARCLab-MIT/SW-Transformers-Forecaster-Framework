####################
## Data
####################
data:
  data_nb: './geodstap_tsr_data.ipynb'
  df_save_path: './preprocessed_data/dataframes/geodstap_tsr.pkl'
  preproc_pipe_save_path: './preprocessed_data/pipelines/preproc_geodstap_tsr.pkl'
  exp_pipe_save_path: './preprocessed_data/pipelines/exp_geodstap_tsr.pkl'
  tsa_model: 'additive'
  data_columns: 
    - DST_Trend
    - DST_Seasonal
    - DST_Residual
    - AP_Trend
    - AP_Seasonal
    - AP_Residual

####################
## Train
####################
train:
  trend_arch_name: 'LSTMAttention'
  seasonal_arch_name: 'LSTMAttention'
  residual_arch_name: 'GRUAttention'
  n_epoch: 10  # Number of epochs to train for
  partial_n: .1 # null uses all training set, float in [0,1] uses a percentage, list filters valid too
  bs: 128 # Batch size
  horizon: 48 # same as paper by Licata et al. (2020)
  init_weights: False  # Kaiming init weights
  lookback: 144 # 3 times the horizon
  lr_max: null # Maximum learning rate. If none, it will be computed with fastai's LRFinder
  metrics_handler_path: null
  main_metric: default

   # If you are using losses that require from aditional parameters, put them here. Those are:
   #  - Hubber and wHubber: delta
   #  - Quantile and wQuantile: quantile
   #  - Classification: primary_loss (plus all the parameters the primary loss may need), alpha
   #  - Trended: primary_loss 
  trend_loss_func: wMAE
  trend_loss_config: {}
  seasonal_loss_func: Quantile
  seasonal_loss_config: {'quantile': 0.9}
  residual_loss_func: wRMSLE
  residual_loss_config: {}

