arch_name: "PatchTST" # See `all_arch_names` in tsasi
bs: 16 # Batch size
horizon: 6 # same as paper by Licata et al. (2020)
init_weights: True  # Kaiming init weights
lookback: 36 
lr_max: null # Maximum learning rate. If none, it will be computed with fastai's LRFinder
n_epoch: 5 # Number of epochs to train for
partial_n: .1 # null uses all training set, float in [0,1] uses a percentage, list filters valid too
seed: 42 # Random seed (null for random)
use_wandb: False # To use it, the environment variable WANDB_API_KEY must be set
wandb_group: null # Useful to group runs that belong to the same optuna study
wandb_log_learner: True # Log learner to wandb
wandb_mode: 'online' # 'online' or 'offline' for wandb
wandb_project: 'swdf' # Name of wandb project