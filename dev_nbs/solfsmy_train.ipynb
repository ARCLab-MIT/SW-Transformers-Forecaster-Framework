{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only needed if the notebook is run in VSCode\n",
    "from IPython.display import clear_output, DisplayHandle\n",
    "def update_patch(self, obj):\n",
    "    clear_output(wait=True)\n",
    "    self.display(obj)\n",
    "DisplayHandle.update = update_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import sklearn\n",
    "from tsai.basics import *\n",
    "from swdf.utils import *\n",
    "my_setup(sklearn)\n",
    "from matplotlib import dates as mdates\n",
    "import wandb\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.progress import ShowGraphCallback\n",
    "from itertools import combinations, chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only needed for the MIT supercloud, to fix fastai's LRFinder error \n",
    "if torch.cuda.is_available() and torch.cuda.device_count() == 0:\n",
    "    from fastai.callback.schedule import LRFinder\n",
    "\n",
    "    @patch_to(LRFinder)\n",
    "    def after_fit(self):\n",
    "        self.learn.opt.zero_grad() # Needed before detaching the optimizer for future fits\n",
    "        tmp_f = self.path/self.model_dir/self.tmp_p/'_tmp.pth'\n",
    "        if tmp_f.exists():\n",
    "            self.learn.load(f'{self.tmp_p}/_tmp', with_opt=True, device='cpu')\n",
    "            self.tmp_d.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting solar drivers F10, S10, M10 and Y10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints about hyperparameters:\n",
    "- According to the authors of PatchTST: \"The ideal patch length may depend on the dataset, \n",
    "but P between {8, 16} seems to be general good numbers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_base = yaml2dict('./config/base.yaml', attrdict=True)\n",
    "config_solfsmy = yaml2dict('./config/solfsmy.yaml', attrdict=True)\n",
    "config_solfsmy = config_solfsmy.train\n",
    "# Merge the two configs (the second one overrides the first one for any keys that are present in both)\n",
    "config = AttrDict({**config_base, **config_solfsmy})\n",
    "# Add the architecture config\n",
    "if config.arch_name.lower() == 'patchtst':\n",
    "    config.arch = yaml2dict('./config/patchtst.yaml', attrdict=True)\n",
    "else:\n",
    "    config.arch = AttrDict()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=config.wandb.project, \n",
    "                 config=config,\n",
    "                 group=config.wandb.group,\n",
    "                 mode=config.wandb.mode, \n",
    "                 anonymous='never') if config.wandb.enabled else None\n",
    "config = dict2attrdict(run.config) if config.wandb.enabled else config\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = config.data_path if config.data_url is None else download_data(config.data_url,\n",
    "                                                                       fname=config.data_path)\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file into a pandas DataFrame, ignoring the lines starting with '#'\n",
    "# Column names: YYYY DDD   JulianDay  F10   F81c  S10   S81c  M10   M81c  Y10   Y81c  Ssrc\n",
    "df_raw = pd.read_csv(fname, delim_whitespace=True, comment='#', header=None, \n",
    "                 names=['Year', 'DDD', 'JulianDay', 'F10', 'F81c', 'S10', 'S81c', \n",
    "                        'M10', 'M81c', 'Y10', 'Y81c', 'Ssrc'])\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F10, S10, M10, and Y10 (81c) have different observation and report times; to standardize reporting, all values are reported in sfu units at 12UT (Universal Time); observations are 3-times daily for F10 (20 UT used), every 5 minutes for S10 (daily average used), twice daily for M10 (7 and 16 UT), and every 1 minute for Y10 (Xrays are each minute while Lya is daily); \n",
    "\n",
    "For model inputs the values should be used as a daily value between 0-24 UT for a given calendar date; F10 and S10 are 1-day lagged, M10 is 2-day, and Y10 is 5-day lagged in JB2008; the 81-day centered values are used with the same respective lag times. Ssrc has 4 fields (1 for each index): \n",
    "\n",
    "*  0 = (F10, S10, M10, Y10) spline-filled if value or missing if no value; \n",
    "* 1 = (F10, M10, Y10) derived or measured index, (S10) SOHO/SEM; \n",
    "* 2 = (S10) TIMED/SEE v11; \n",
    "* 3 = (S10) SOHO gap (daily); \n",
    "* 4 = (S10) SOHO gap (average); \n",
    "* 5 = (F10) F10 mean (2 surrounding values), (S10) SDO/EVE; \n",
    "* 6 = (S10) GOES/EUVS fill-in, (M10) M10 mean (2 surrounding values); \n",
    "* 7 = (S10) S10 scaled to match M10 change from previous day; \n",
    "* 8 = (S10) SDO/EVE corrections and all S10 tweaked from sat 12388 delta B%, (Y10) UARS/SOLSTICE V18; \n",
    "* 9 = (S10) replace original v4.0h data for versions 4.0 and higher, (Y10) UARS/SOLSTICE v19; \n",
    "* A = (S10) TIMED/SEE solar minimum correction; \n",
    "* B = (S10) replace with original v4.0h S10 data for versions 4.0 and higher, (M10) SORCE/SOLSTICE/SIM v9; \n",
    "* C = (S10) SDO/EVE correction, (Y10) GOES XRS; \n",
    "* D = (S10) validated TIMED/SEE, (Y10) GOES XRS and SET composite LYA; \n",
    "* E = (S10) S10 composite, (Y10) SET composite LYA; \n",
    "* F = (F10, S10, M10, Y10) mean of bordering values\n",
    "\n",
    "Acronyms:\n",
    "* SOHO/SEM: Solar and Heliospheric Observatory/ Spacecraft's Solar Extreme-ultraviolet Monitor (SEM)\n",
    "* SDO/EVE: Solar Dynamics Observatory/Extreme Ultraviolet Variability Experiment.\n",
    "* UARS/SOLSTICE: Upper Atmosphere Research Satellite/Solar Stellar Irradiance Comparison Experiment\n",
    "* SORCE/SOLSTICE/SIM: Solar Radiation and Climate Experiment/SOLSTICE/Spectral Irradiance Monitor\n",
    "* GOES/XRS: Geostationary Operational Environmental Satellite/X-Ray Sensor\n",
    "* \"SET composite LYA\" refers to the solar irradiance in the Lyman-alpha (Lyα) wavelength range, as measured by the Solar EUV Experiment Telescope (SET) onboard the Solar Radiation and Climate Experiment (SORCE) spacecraft.\n",
    "\n",
    "This webpage contains forecasts (paid forecast) that we can use to compare to\n",
    "https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2020SW002496. It's interesting\n",
    "to see what they forecast from the previous data in order to try the same thing \n",
    "with the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_mapping = {\n",
    "    '0': '(F10, S10, M10, Y10) spline-filled if value or missing if no value',\n",
    "    '1': '(F10, M10, Y10) derived or measured index, (S10) SOHO/SEM',\n",
    "    '2': '(S10) TIMED/SEE v11',\n",
    "    '3': '(S10) SOHO gap (daily)',\n",
    "    '4': '(S10) SOHO gap (average)',\n",
    "    '5': '(F10) F10 mean (2 surrounding values), (S10) SDO/EVE',\n",
    "    '6': '(S10) GOES/EUVS fill-in, (M10) M10 mean (2 surrounding values)',\n",
    "    '7': '(S10) S10 scaled to match M10 change from previous day',\n",
    "    '8': '(S10) SDO/EVE corrections and all S10 tweaked from sat 12388 delta B%, (Y10) UARS/SOLSTICE V18',\n",
    "    '9': '(S10) replace original v4.0h data for versions 4.0 and higher, (Y10) UARS/SOLSTICE v19',\n",
    "    'A': '(S10) TIMED/SEE solar minimum correction',\n",
    "    'B': '(S10) replace with original v4.0h S10 data for versions 4.0 and higher, (M10) SORCE/SOLSTICE/SIM v9',\n",
    "    'C': '(S10) SDO/EVE correction, (Y10) GOES XRS',\n",
    "    'D': '(S10) validated TIMED/SEE, (Y10) GOES XRS and SET composite LYA',\n",
    "    'E': '(S10) S10 composite, (Y10) SET composite LYA',\n",
    "    'F': '(F10, S10, M10, Y10) mean of bordering values'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any missing values\n",
    "df_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinct value of the column Ssrc\n",
    "df_raw.Ssrc.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the Ssrc columns into four colums, one for each character of the string,\n",
    "# The names of the new columns will be SsrcF10, SsrcS10, SsrcM10, and SsrcY10,\n",
    "# Cast the new columns into categories. Use a loop\n",
    "for i, c in enumerate('F10 S10 M10 Y10'.split()):\n",
    "    df_raw[f'Ssrc_{c}'] = df_raw['Ssrc'].str[i].astype('category')\n",
    "df_raw[['Ssrc_F10', 'Ssrc_S10', 'Ssrc_M10', 'Ssrc_Y10']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the categories of the column Ssrc_S10\n",
    "df_raw.Ssrc_S10.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the JulianDay column to a datetime column, and set it as index\n",
    "df_raw['Date'] = pd.to_datetime(df_raw['JulianDay'], unit='D', origin='julian')\n",
    "df_raw['Date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the values to use in the\n",
    "S10_legend = [legend_mapping[value] for value in df_raw.Ssrc_S10.cat.categories]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "\n",
    "# Plot the variable S10. The color of the line will be determined by the value of Ssrc_S10\n",
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "scatter = ax.scatter(df_raw.Date, df_raw.S10, c=df_raw.Ssrc_S10.cat.codes, cmap='tab10', s=10)\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('S10')\n",
    "ax.set_title('S10 and Ssrc_S10')\n",
    "\n",
    "# Legend configuration\n",
    "ax.set_ylim(0,max(df_raw.S10)+100)\n",
    "legend = ax.legend(handles=scatter.legend_elements()[0], labels=S10_legend, loc=\"best\", title=\"Origin\")\n",
    "ax.add_artist(legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of values equlas to zero in S10\n",
    "print((df_raw.S10 == 0).sum())\n",
    "# convert them to NA\n",
    "df_raw.loc[df_raw.S10 == 0, 'S10'] = np.nan\n",
    "print((df_raw.S10 == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# plot the variable S10 again\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.scatter(df_raw.Date, df_raw.S10, c=df_raw.Ssrc_S10.cat.codes, cmap='tab10', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_col = 'Date'\n",
    "freq = '1D'\n",
    "data_columns_fcst = config.data_columns_fcst\n",
    "data_columns_time = ['Year', 'DDD']\n",
    "data_columns = data_columns_fcst + data_columns_time if config.add_time_channels else data_columns_fcst\n",
    "imputation_method = 'ffill'\n",
    "\n",
    "# sklearn's preprocessing pipeline\n",
    "preproc_pipe = sklearn.pipeline.Pipeline([\n",
    "    ('shrinker', TSShrinkDataFrame()), # shrik dataframe memory usage and set the right dtypes\n",
    "    ('drop_duplicates', TSDropDuplicates(datetime_col='Date')), # drop duplicates\n",
    "    ('fill_missing', TSFillMissing(columns=data_columns, method=imputation_method, value=None)), # fill missing data (1st ffill. 2nd value=0)\n",
    "], verbose=True)\n",
    "\n",
    "df = preproc_pipe.fit_transform(df_raw)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the paper by Licata et al. (2020) (https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2020SW002496),\n",
    "# authors use a period from October 2012 through the end of 2018 for the benchmarking.\n",
    "# Therefore, we will set the test set as the same period for our analysis, \n",
    "# using the column Date as the timestamp, from October 2012 to the end of 2018. \n",
    "# Everything before the test set will be used for training, and everything after the test set\n",
    "# will be used for validation\n",
    "test_start_datetime = config.test_start_datetime\n",
    "test_end_datetime = config.test_end_datetime\n",
    "valid_start_datetime = config.valid_start_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide \n",
    "\n",
    "# Plot the variables F10, S10, M10 and Y10, covering the different periods (training, test and validation)\n",
    "# with different colors. Do it for the 4 variables mentioned above \n",
    "fig, ax = plt.subplots(4, 1, figsize=(20, 10))\n",
    " \n",
    "for i, var in enumerate(['F10', 'S10', 'M10', 'Y10']):\n",
    "    ax[i].plot(df[var], label='train')\n",
    "    ax[i].plot(df[var][(df.Date >= test_start_datetime) & (df.Date <= test_end_datetime)],\n",
    "               label='test')\n",
    "    ax[i].plot(df[var][(df.Date >= valid_start_datetime)], label='valid')\n",
    "    ax[i].set_title(var)\n",
    "    ax[i].legend()\n",
    "    ax[i].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d')) # format x-axis ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranges extracted from [Licata, Tobiska, y Mehta, «Benchmarking Forecasting Models for Space Weather Drivers»](https://onlinelibrary.wiley.com/doi/abs/10.1029/2020SW002496)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thresholds = {\n",
    "    'F10':  [(0,75), (76,150), (151,190), (191, df['F10'].max())],\n",
    "    'S10': [(0,65), (66,150), (151,215), (216, df['S10'].max())],\n",
    "    'M10': [(0,72), (73,144), (145,167), (168, df['M10'].max())],\n",
    "    'Y10': [(0,81), (82,148), (149,165), (166, df['Y10'].max())]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = get_classified_columns(df_raw, thresholds)\n",
    "df['Cat'] = df_cat['F10_Cat'].replace(to_replace=get_F10_historical_distribution(thresholds))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_period = (df_raw.Date >= test_start_datetime) & (df_raw.Date <= test_end_datetime)\n",
    "\n",
    "df_cat = get_classified_columns(df_raw, thresholds)\n",
    "df_cat = df_cat[~(test_period)]\n",
    "\n",
    "historical_distribution = get_F10_historical_distribution(thresholds)\n",
    "\n",
    "# Function parameter calculation\n",
    "test_size = df[test_period].shape[0] / df.shape[0]\n",
    "train_val_size = 1 - test_size\n",
    "val_size = 0.15 / train_val_size\n",
    "print(f\"Test size: {test_size}, Validation size: {val_size}, Train size: {1 - test_size - 0.15}\")\n",
    "\n",
    "# Best segment size found: 250, val_size: 0.15, test_size: 0.65\n",
    "best_comb, segments, distribution = find_closest_distribution(df_cat['F10_Cat'], historical_distribution, 250, val_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_comb_idxs = [segments[i] for i in best_comb]\n",
    "validation = df.loc[chain.from_iterable(best_comb_idxs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_segments = (df.index.isin(chain.from_iterable(best_comb_idxs)))\n",
    "train_df = df[~validation_segments & ~test_period] \n",
    "train_distribution = get_classified_columns(train_df, thresholds)['F10_Cat'].value_counts(normalize=True).to_dict()\n",
    "\n",
    "train_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# Plot of the distribution found\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(distribution.keys(), distribution.values(), alpha=0.8, label='Validation Distribution')\n",
    "plt.bar(historical_distribution.keys(), historical_distribution.values(), alpha=0.5, label='Historical Distribution')\n",
    "plt.bar(train_distribution.keys(), train_distribution.values(), alpha=0.5, label='Train Distribution')\n",
    "\n",
    "plt.xlabel('Solar activity categories')\n",
    "plt.ylabel('Percentage of data')\n",
    "plt.title('Solar Activity Categories Distribution Comparison of F10.7')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot of the future splits\n",
    "fig, ax = plt.subplots(4, 1, figsize=(20, 10))\n",
    "\n",
    "for i, var in enumerate(['F10', 'S10', 'M10', 'Y10']):\n",
    "    ax[i].plot(df.Date, df[var], label='train')\n",
    "    ax[i].plot(df.Date[(df.Date >= test_start_datetime) & (df.Date <= test_end_datetime)],\n",
    "               df[var][(df.Date >= test_start_datetime) & (df.Date <= test_end_datetime)],\n",
    "               label='test')\n",
    "    ax[i].plot(validation.Date,\n",
    "               validation[var],\n",
    "               label='validation')\n",
    "    ax[i].set_title(var)\n",
    "    ax[i].legend()\n",
    "    ax[i].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d')) # format x-axis ticks\n",
    "    \n",
    "    set_ranges = np.zeros((int(df[var].max()), df.shape[0],4)) # (Height, Width)\n",
    "\n",
    "    for j, (start, end) in enumerate(thresholds[var]):\n",
    "        set_ranges[int(start):int(end), :, :] = [0,0,0, ((j+1)/4)]\n",
    "   \n",
    "    ax[i].imshow(set_ranges, extent=[df.Date.min(), df.Date.max(), 0, df[var].max()], aspect='auto', alpha=0.5, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import more_itertools as mit\n",
    "\n",
    "def sliding_window_generator(df, split_start, comb=None, segments=None):\n",
    "    consecutive_elements, X, y = None, None, None\n",
    "\n",
    "    if comb is not None:\n",
    "        consecutive_elements = [list(group) for group in mit.consecutive_groups(comb)]\n",
    "\n",
    "        df_to_window = []\n",
    "        for elements in consecutive_elements:\n",
    "            best_comb_idxs = [segments[i] for i in elements]\n",
    "            df_to_window.append(df.iloc[chain.from_iterable(best_comb_idxs)])\n",
    "    else:\n",
    "        df_to_window = [df]\n",
    "\n",
    "    X_window, y_window = None, None \n",
    "    for df_window in df_to_window:    \n",
    "        X_window, y_window = SlidingWindow(\n",
    "            window_len=config.lookback,\n",
    "            horizon=config.horizon, \n",
    "            stride=1, \n",
    "            get_x=data_columns, \n",
    "            get_y=data_columns\n",
    "        )(df_window)\n",
    "        \n",
    "        X = np.concatenate([X, X_window]) if X is not None else X_window\n",
    "        y = np.concatenate([y, y_window]) if y is not None else y_window\n",
    "    \n",
    "    \n",
    "    splits = L(list(np.arange(split_start, len(X)+split_start)))\n",
    "    return X, y, splits\n",
    "\n",
    "a = np.arange(0,len(segments))\n",
    "train_comb = list(np.setdiff1d(a, best_comb))\n",
    "\n",
    "X_val, y_val, split_val = sliding_window_generator(df, 0, comb=best_comb, segments=segments)\n",
    "X_train, y_train, split_train = sliding_window_generator(df, split_val[-1]+1, comb=train_comb, segments=segments)\n",
    "X_test, y_test, split_test = sliding_window_generator(df[test_period], split_train[-1]+1) \n",
    "\n",
    "X = np.concatenate([X_val, X_train, X_test])\n",
    "y = np.concatenate([y_val, y_train, y_test])\n",
    "\n",
    "splits = (split_train, split_val, split_test)\n",
    "splits, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have defined the splits for this particular experiment, we'll scale\n",
    "# the data\n",
    "train_split = splits[0]\n",
    "exp_pipe = sklearn.pipeline.Pipeline([\n",
    "    ('scaler', TSStandardScaler(columns=data_columns)),\n",
    "], verbose=True)\n",
    "save_object(exp_pipe, 'tmp/exp_pipe.pkl')\n",
    "exp_pipe = load_object('tmp/exp_pipe.pkl')\n",
    "# TODO: I don't know why but if I don't copy the dataframe df it gets modified\n",
    "df_scaled = exp_pipe.fit_transform(df.copy(), scaler__idxs = train_split)\n",
    "#df_scaled.set_index(datetime_col, inplace=True)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Apply a sliding window. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsai.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_callback = WandbCallback(log_preds=False)\n",
    "cbs = L(wandb_callback) if config.wandb.enabled else L()\n",
    "learn = TSForecaster(X, y, splits=splits, batch_size=config.bs,\n",
    "                     pipelines=[preproc_pipe, exp_pipe], arch=config.arch_name, \n",
    "                     arch_config=dict(config.arch), \n",
    "                     init=config.init_weights,\n",
    "                     cbs= cbs + ShowGraphCallback(), \n",
    "                     partial_n=config.partial_n)\n",
    "lr_max = learn.lr_find().valley if config.lr_max is None else config.lr_max\n",
    "print(lr_max)\n",
    "print(f\"#params: {sum(p.numel() for p in learn.model.parameters())}\")\n",
    "learn.fit_one_cycle(n_epoch=config.n_epoch, lr_max=config.lr_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the validation loss and save it in case other notebooks (optuna) wants to\n",
    "# use it for hyperparameter optimization\n",
    "valid_loss = learn.validate()[0] \n",
    "print(valid_loss)\n",
    "%store valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the test loss to wandb\n",
    "test_loss = learn.validate(ds_idx=2)[0]\n",
    "print(test_loss)\n",
    "if run is not None:\n",
    "    run.log(dict(test_loss=test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything\n",
    "learn.dls.loaders += [learn.dls.valid.new_dl(X[splits[2]], y[splits[2]])] # Add test datalaoder\n",
    "# Remove the wandb callback to avoid errors when downloading the learner\n",
    "if config.wandb.enabled:\n",
    "    learn.remove_cb(wandb_callback)\n",
    "\n",
    "# Save locally and in wandb if online and enabled\n",
    "learn.save_all(path='tmp', verbose=True) \n",
    "if run is not None and config.wandb_mode and config.wandb_log_learner:\n",
    "    # Save the learner (all tmp/dls, tmp/model.pth, and tmp/learner.pkl). \n",
    "    run.log_artifact('tmp', type='learner', name='solfsmy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run is not None:\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
