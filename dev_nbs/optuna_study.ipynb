{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna study\n",
    "\n",
    "> Combine it with papermill and wandb for seamless hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/pip-global/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import optuna\n",
    "from tsai.optuna import *\n",
    "import papermill as pm\n",
    "from tsai.optuna import run_optuna_study\n",
    "from fastcore.basics import *\n",
    "from optuna.distributions import *\n",
    "from optuna.samplers import TPESampler\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AttrDict(\n",
    "    study_name = 'general_study_extended', # name of the Optuna study\n",
    "    study_type = 'bayesian', # 'bayesian' or 'gridsearch' or 'random'\n",
    "    n_trials = 50, # number of trials\n",
    "    train_nb = f'{os.getcwd()}/solfsmy_train.ipynb', # path to the notebook to be executed\n",
    "    search_space = {\n",
    "        \"arch.attn_dropout\": DiscreteUniformDistribution(0.0, 0.5, 0.1),\n",
    "        \"arch.d_model\": IntUniformDistribution(32, 512, 32),\n",
    "        \"arch.d_ff\": IntUniformDistribution(32, 512, 32),\n",
    "        \"arch.decomposition\": CategoricalDistribution([True, False]),\n",
    "        \"arch.dropout\": DiscreteUniformDistribution(0.0, 0.5, 0.1), \n",
    "        \"arch.individual\": CategoricalDistribution([True, False]),\n",
    "        \"arch.n_layers\": IntUniformDistribution(1, 6, 1),\n",
    "        \"arch.n_heads\": CategoricalDistribution([2, 4, 8, 16, 32]),\n",
    "        \"init_weights\": CategoricalDistribution([True, False]), # true = kaiming\n",
    "        \"lookback\": CategoricalDistribution([18, 24, 36, 128, 192])  # Change here\n",
    "    },\n",
    "    # Add extra parameters that are fixed, but not part of the search space\n",
    "    extra_params = {\n",
    "        \"n_epoch\": 50,\n",
    "        \"bs\": 128\n",
    "    },\n",
    "    use_wandb = True,\n",
    "    wandb_mode = 'offline'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_objective(train_nb, search_space, extra_params=None, use_wandb=False):\n",
    "    \"\"\"\n",
    "        Create objective function to be minimized by Optuna.\n",
    "        Inputs:\n",
    "            trial: Optuna trial object\n",
    "            train_nb: path to the training notebook\n",
    "            search_vars: keys of the search space to be used\n",
    "            wandb_group: name of the wandb group to be used\n",
    "        Output:\n",
    "            valid_loss: validation loss\n",
    "    \"\"\"\n",
    "    def objective(trial:optuna.Trial):\n",
    "        # Define the parameters to be passed to the training notebook through papermill\n",
    "        pm_parameters = {}\n",
    "        for k,v in search_space.items():\n",
    "            pm_parameters['config.' + k] = trial._suggest(k, v)\n",
    "\n",
    "        # Add the extra parameters to the dictionary. The key of every parameter \n",
    "        # must be 'config.<param_name>'\n",
    "        if extra_params is not None:\n",
    "            for k,v in extra_params.items():\n",
    "                pm_parameters['config.' + k] = v\n",
    "                \n",
    "        # If using wandb, enable that in the training runs, all of them gathered\n",
    "        # into a group (NOTE: The train nb must have and use these config arguments)\n",
    "        if use_wandb:\n",
    "            pm_parameters['config.use_wandb'] = True\n",
    "            pm_parameters['config.wandb_group'] = config.study_name + '_runs'\n",
    "\n",
    "        # Call the training notebook using papermill (don't print the output)\n",
    "        stdout_file = open('tmp/pm_stdout.txt', 'w')\n",
    "        stderr_file = open('tmp/pm_stderr.txt', 'w')\n",
    "\n",
    "        pm.execute_notebook(\n",
    "            train_nb,\n",
    "            './tmp/pm_output.ipynb',\n",
    "            parameters = pm_parameters,\n",
    "            stdout_file = stdout_file,\n",
    "            stderr_file = stderr_file\n",
    "        )\n",
    "\n",
    "        # Close the output files\n",
    "        stdout_file.close()\n",
    "        stderr_file.close()\n",
    "\n",
    "        # Get the output value of interest from the source notebook\n",
    "        %store -r valid_loss\n",
    "        return valid_loss\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-05 11:09:17,373] A new study created in memory with name: general_study_extended\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]Passed unknown parameter: config.arch.attn_dropout\n",
      "Passed unknown parameter: config.arch.d_model\n",
      "Passed unknown parameter: config.arch.d_ff\n",
      "Passed unknown parameter: config.arch.decomposition\n",
      "Passed unknown parameter: config.arch.dropout\n",
      "Passed unknown parameter: config.arch.individual\n",
      "Passed unknown parameter: config.arch.n_layers\n",
      "Passed unknown parameter: config.arch.n_heads\n",
      "Passed unknown parameter: config.init_weights\n",
      "Passed unknown parameter: config.lookback\n",
      "Passed unknown parameter: config.n_epoch\n",
      "Passed unknown parameter: config.bs\n",
      "Passed unknown parameter: config.use_wandb\n",
      "Passed unknown parameter: config.wandb_group\n",
      "Input notebook does not contain a cell with tag 'parameters'\n",
      "Executing:   2%|â–         | 1/46 [00:01<01:07,  1.51s/cell]\n",
      "  0%|          | 0/50 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2024-07-05 11:09:19,022] Trial 0 failed with parameters: {'arch.attn_dropout': 0.30000000000000004, 'arch.d_model': 160, 'arch.d_ff': 96, 'arch.decomposition': True, 'arch.dropout': 0.0, 'arch.individual': True, 'arch.n_layers': 2, 'arch.n_heads': 2, 'init_weights': False, 'lookback': 18} because of the following error: PapermillExecutionError(0, 1, '# Parameters\\nconfig.arch.attn_dropout = 0.30000000000000004\\nconfig.arch.d_model = 160\\nconfig.arch.d_ff = 96\\nconfig.arch.decomposition = True\\nconfig.arch.dropout = 0.0\\nconfig.arch.individual = True\\nconfig.arch.n_layers = 2\\nconfig.arch.n_heads = 2\\nconfig.init_weights = False\\nconfig.lookback = 18\\nconfig.n_epoch = 50\\nconfig.bs = 128\\nconfig.use_wandb = True\\nconfig.wandb_group = \"general_study_extended_runs\"\\n', 'NameError', \"name 'config' is not defined\", ['\\x1b[0;31m---------------------------------------------------------------------------\\x1b[0m', '\\x1b[0;31mNameError\\x1b[0m                                 Traceback (most recent call last)', 'Cell \\x1b[0;32mIn[1], line 2\\x1b[0m\\n\\x1b[1;32m      1\\x1b[0m \\x1b[38;5;66;03m# Parameters\\x1b[39;00m\\n\\x1b[0;32m----> 2\\x1b[0m \\x1b[43mconfig\\x1b[49m\\x1b[38;5;241m.\\x1b[39march\\x1b[38;5;241m.\\x1b[39mattn_dropout \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;241m0.30000000000000004\\x1b[39m\\n\\x1b[1;32m      3\\x1b[0m config\\x1b[38;5;241m.\\x1b[39march\\x1b[38;5;241m.\\x1b[39md_model \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;241m160\\x1b[39m\\n\\x1b[1;32m      4\\x1b[0m config\\x1b[38;5;241m.\\x1b[39march\\x1b[38;5;241m.\\x1b[39md_ff \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;241m96\\x1b[39m\\n', \"\\x1b[0;31mNameError\\x1b[0m: name 'config' is not defined\"]).\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/pip-global/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_5541/3232688709.py\", line 34, in objective\n",
      "    pm.execute_notebook(\n",
      "  File \"/usr/local/pip-global/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/pip-global/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "NameError                                 Traceback (most recent call last)\n",
      "Cell In[1], line 2\n",
      "      1 # Parameters\n",
      "----> 2 config.arch.attn_dropout = 0.30000000000000004\n",
      "      3 config.arch.d_model = 160\n",
      "      4 config.arch.d_ff = 96\n",
      "\n",
      "NameError: name 'config' is not defined\n",
      "\n",
      "[W 2024-07-05 11:09:19,029] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "PapermillExecutionError",
     "evalue": "\n---------------------------------------------------------------------------\nException encountered at \"In [1]\":\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[1], line 2\n      1 # Parameters\n----> 2 config.arch.attn_dropout = 0.30000000000000004\n      3 config.arch.d_model = 160\n      4 config.arch.d_ff = 96\n\nNameError: name 'config' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPapermillExecutionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m obj \u001b[38;5;241m=\u001b[39m create_objective(config\u001b[38;5;241m.\u001b[39mtrain_nb, config\u001b[38;5;241m.\u001b[39msearch_space, \n\u001b[1;32m      2\u001b[0m                        extra_params\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mextra_params, use_wandb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43mrun_optuna_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbayesian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mminimize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./tmp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstudy_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/pip-global/tsai/optuna.py:80\u001b[0m, in \u001b[0;36mrun_optuna_study\u001b[0;34m(objective, resume, study_type, multivariate, search_space, evaluate, seed, sampler, pruner, study_name, direction, n_trials, timeout, gc_after_trial, show_progress_bar, save_study, path, show_plots)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate: study\u001b[38;5;241m.\u001b[39menqueue_trial(evaluate)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/pip-global/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/pip-global/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/pip-global/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/pip-global/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/pip-global/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m, in \u001b[0;36mcreate_objective.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     31\u001b[0m stdout_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp/pm_stdout.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m stderr_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp/pm_stderr.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_notebook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_nb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./tmp/pm_output.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpm_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstdout_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstdout_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstderr_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstderr_file\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Close the output files\u001b[39;00m\n\u001b[1;32m     43\u001b[0m stdout_file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/pip-global/papermill/execute.py:131\u001b[0m, in \u001b[0;36mexecute_notebook\u001b[0;34m(input_path, output_path, parameters, engine_name, request_save_on_cell_execute, prepare_only, kernel_name, language, progress_bar, log_output, stdout_file, stderr_file, start_timeout, report_mode, cwd, **engine_kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         nb \u001b[38;5;241m=\u001b[39m papermill_engines\u001b[38;5;241m.\u001b[39mexecute_notebook_with_engine(\n\u001b[1;32m    117\u001b[0m             engine_name,\n\u001b[1;32m    118\u001b[0m             nb,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[1;32m    128\u001b[0m         )\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# Check for errors first (it saves on error before raising)\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     \u001b[43mraise_for_execution_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Write final output in case the engine didn't write it on cell completion.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m write_ipynb(nb, output_path)\n",
      "File \u001b[0;32m/usr/local/pip-global/papermill/execute.py:251\u001b[0m, in \u001b[0;36mraise_for_execution_errors\u001b[0;34m(nb, output_path)\u001b[0m\n\u001b[1;32m    248\u001b[0m nb\u001b[38;5;241m.\u001b[39mcells\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, error_msg_cell)\n\u001b[1;32m    250\u001b[0m write_ipynb(nb, output_path)\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mPapermillExecutionError\u001b[0m: \n---------------------------------------------------------------------------\nException encountered at \"In [1]\":\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[1], line 2\n      1 # Parameters\n----> 2 config.arch.attn_dropout = 0.30000000000000004\n      3 config.arch.d_model = 160\n      4 config.arch.d_ff = 96\n\nNameError: name 'config' is not defined\n"
     ]
    }
   ],
   "source": [
    "obj = create_objective(config.train_nb, config.search_space, \n",
    "                       extra_params=config.extra_params, use_wandb=True)\n",
    "study = run_optuna_study(obj, study_type='bayesian', direction='minimize', path='./tmp',\n",
    "                 study_name=config.study_name, n_trials=config.n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(config=config, mode=config.wandb_mode, \n",
    "                 job_type='optuna-study') if config.use_wandb else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run is not None:\n",
    "    run.log(dict(study.best_params, **{'best_value': study.best_value, \n",
    "                                       'best_trial_number': study.best_trial.number}))\n",
    "    run.log_artifact(f'./tmp/{config.study_name}.pkl', type='optuna_study')\n",
    "    run.log({\n",
    "        'contour': optuna.visualization.plot_contour(study),\n",
    "        'edf': optuna.visualization.plot_edf(study),\n",
    "        'intermediate_values': optuna.visualization.plot_intermediate_values(study),\n",
    "        'optimization_history': optuna.visualization.plot_optimization_history(study),\n",
    "        'parallel_coordinate' : optuna.visualization.plot_parallel_coordinate(study),\n",
    "        'param_importances': optuna.visualization.plot_param_importances(study),\n",
    "        'slice': optuna.visualization.plot_slice(study)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run is not None:\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
