{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna study\n",
    "\n",
    "> Combine it with papermill and wandb for seamless hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "from tsai.optuna import *\n",
    "import papermill as pm\n",
    "from tsai.optuna import run_optuna_study\n",
    "from fastcore.basics import *\n",
    "from optuna.distributions import *\n",
    "from optuna.samplers import TPESampler\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AttrDict(\n",
    "    study_name = 'general_study_extended', # name of the Optuna study\n",
    "    study_type = 'bayesian', # 'bayesian' or 'gridsearch' or 'random'\n",
    "    n_trials = 50, # number of trials\n",
    "    train_nb = f'{os.getcwd()}/dev_nbs/solfsmy_train.ipynb', # path to the notebook to be executed\n",
    "    search_space = {\n",
    "        \"arch.attn_dropout\": DiscreteUniformDistribution(0.0, 0.5, 0.1),\n",
    "        \"arch.d_model\": IntUniformDistribution(32, 512, 32),\n",
    "        \"arch.d_ff\": IntUniformDistribution(32, 512, 32),\n",
    "        \"arch.decomposition\": CategoricalDistribution([True, False]),\n",
    "        \"arch.dropout\": DiscreteUniformDistribution(0.0, 0.5, 0.1), \n",
    "        \"arch.individual\": CategoricalDistribution([True, False]),\n",
    "        \"arch.n_layers\": IntUniformDistribution(1, 6, 1),\n",
    "        \"arch.n_heads\": CategoricalDistribution([2, 4, 8, 16, 32]),\n",
    "        \"init_weights\": CategoricalDistribution([True, False]), # true = kaiming\n",
    "        \"lookback\": IntUniformDistribution([18, 24, 36, 128, 192])\n",
    "    },\n",
    "    # Add extra parameters that are fixed, but not part of the search space\n",
    "    extra_params = {\n",
    "        \"n_epoch\": 50,\n",
    "        \"bs\": 128\n",
    "    },\n",
    "    use_wandb = True,\n",
    "    wandb_mode = 'offline'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_objective(train_nb, search_space, extra_params=None, use_wandb=False):\n",
    "    \"\"\"\n",
    "        Create objective function to be minimized by Optuna.\n",
    "        Inputs:\n",
    "            trial: Optuna trial object\n",
    "            train_nb: path to the training notebook\n",
    "            search_vars: keys of the search space to be used\n",
    "            wandb_group: name of the wandb group to be used\n",
    "        Output:\n",
    "            valid_loss: validation loss\n",
    "    \"\"\"\n",
    "    def objective(trial:optuna.Trial):\n",
    "        # Define the parameters to be passed to the training notebook through papermill\n",
    "        pm_parameters = {}\n",
    "        for k,v in search_space.items():\n",
    "            pm_parameters['config.' + k] = trial._suggest(k, v)\n",
    "\n",
    "        # Add the extra parameters to the dictionary. The key of every parameter \n",
    "        # must be 'config.<param_name>'\n",
    "        if extra_params is not None:\n",
    "            for k,v in extra_params.items():\n",
    "                pm_parameters['config.' + k] = v\n",
    "                \n",
    "        # If using wandb, enable that in the training runs, all of them gathered\n",
    "        # into a group (NOTE: The train nb must have and use these config arguments)\n",
    "        if use_wandb:\n",
    "            pm_parameters['config.use_wandb'] = True\n",
    "            pm_parameters['config.wandb_group'] = config.study_name + '_runs'\n",
    "\n",
    "        # Call the training notebook using papermill (don't print the output)\n",
    "        stdout_file = open('tmp/pm_stdout.txt', 'w')\n",
    "        stderr_file = open('tmp/pm_stderr.txt', 'w')\n",
    "\n",
    "        pm.execute_notebook(\n",
    "            train_nb,\n",
    "            './tmp/pm_output.ipynb',\n",
    "            parameters = pm_parameters,\n",
    "            stdout_file = stdout_file,\n",
    "            stderr_file = stderr_file\n",
    "        )\n",
    "\n",
    "        # Close the output files\n",
    "        stdout_file.close()\n",
    "        stderr_file.close()\n",
    "\n",
    "        # Get the output value of interest from the source notebook\n",
    "        %store -r valid_loss\n",
    "        return valid_loss\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = create_objective(config.train_nb, config.search_space, \n",
    "                       extra_params=config.extra_params, use_wandb=True)\n",
    "study = run_optuna_study(obj, study_type='bayesian', direction='minimize', path='./tmp',\n",
    "                 study_name=config.study_name, n_trials=config.n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(config=config, mode=config.wandb_mode, \n",
    "                 job_type='optuna-study') if config.use_wandb else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run is not None:\n",
    "    run.log(dict(study.best_params, **{'best_value': study.best_value, \n",
    "                                       'best_trial_number': study.best_trial.number}))\n",
    "    run.log_artifact(f'./tmp/{config.study_name}.pkl', type='optuna_study')\n",
    "    run.log({\n",
    "        'contour': optuna.visualization.plot_contour(study),\n",
    "        'edf': optuna.visualization.plot_edf(study),\n",
    "        'intermediate_values': optuna.visualization.plot_intermediate_values(study),\n",
    "        'optimization_history': optuna.visualization.plot_optimization_history(study),\n",
    "        'parallel_coordinate' : optuna.visualization.plot_parallel_coordinate(study),\n",
    "        'param_importances': optuna.visualization.plot_param_importances(study),\n",
    "        'slice': optuna.visualization.plot_slice(study)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run is not None:\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
