{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna study\n",
    "\n",
    "> Combine it with papermill and wandb for seamless hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "from tsai.optuna import *\n",
    "import papermill as pm\n",
    "from tsai.optuna import run_optuna_study\n",
    "from fastcore.basics import *\n",
    "from optuna.distributions import *\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AttrDict(\n",
    "    study_name = 'general', # name of the Optuna study\n",
    "    study_type = 'bayesian', # 'bayesian' or 'gridsearch' or 'random'\n",
    "    n_trials = 2, # number of trials\n",
    "    train_nb = f'{os.getcwd()}/training.ipynb', # path to the notebook to be executed\n",
    "    search_space = {\n",
    "        \"arch.attn_dropout\": DiscreteUniformDistribution(0.0, 0.5, 0.1),\n",
    "        \"arch.dropout\": DiscreteUniformDistribution(0.0, 0.5, 0.1),\n",
    "        \"arch.d_model\": IntUniformDistribution(32, 512, 32),\n",
    "        \"arch.n_layers\": IntUniformDistribution(1, 6, 1),\n",
    "        \"arch.n_heads\": IntUniformDistribution(1, 8, 1),\n",
    "        \"arch.d_ff\": IntUniformDistribution(32, 512, 32),\n",
    "        \"init_weights\": CategoricalDistribution([True, False]), # true = kaiming\n",
    "    },\n",
    "    # Add extra parameters that are fixed, but not part of the search space\n",
    "    extra_params = {\n",
    "        \"n_epoch\": 1,\n",
    "        \"bs\": 128,\n",
    "        \"use_wandb\": True,\n",
    "        \"wandb_group\": config.study_name\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_objective(train_nb, search_space, extra_params=None):\n",
    "    \"\"\"\n",
    "        Create objective function to be minimized by Optuna.\n",
    "        Inputs:\n",
    "            trial: Optuna trial object\n",
    "            train_nb: path to the training notebook\n",
    "            search_vars: keys of the search space to be used\n",
    "            wandb_group: name of the wandb group to be used\n",
    "        Output:\n",
    "            valid_loss: validation loss\n",
    "    \"\"\"\n",
    "    def objective(trial:optuna.Trial):\n",
    "        # Define the parameters to be passed to the training notebook through papermill\n",
    "        pm_parameters = {}\n",
    "        for k,v in search_space.items():\n",
    "            pm_parameters['config.' + k] = trial._suggest(k, v)\n",
    "\n",
    "        # Add the extra parameters to the dictionary. The key of every parameter \n",
    "        # must be 'config.<param_name>'\n",
    "        if extra_params is not None:\n",
    "            for k,v in extra_params.items():\n",
    "                pm_parameters['config.' + k] = v\n",
    "\n",
    "        # Call the training notebook using papermill (don't print the output)\n",
    "        stdout_file = open('tmp/pm_stdout.txt', 'w')\n",
    "        stderr_file = open('tmp/pm_stderr.txt', 'w')\n",
    "\n",
    "        pm.execute_notebook(\n",
    "            train_nb,\n",
    "            './tmp/pm_output.ipynb',\n",
    "            parameters = pm_parameters,\n",
    "            stdout_file = stdout_file,\n",
    "            stderr_file = stderr_file\n",
    "        )\n",
    "\n",
    "        # Close the output files\n",
    "        stdout_file.close()\n",
    "        stderr_file.close()\n",
    "\n",
    "        # Get the output value of interest from the source notebook\n",
    "        %store -r valid_loss\n",
    "        return valid_loss\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-24 21:12:25,656]\u001b[0m A new study created in memory with name: general\u001b[0m\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]Black is not installed, parameters wont be formatted\n",
      "Executing:  91%|█████████ | 29/32 [05:56<00:36, 12.30s/cell]\n",
      "  0%|          | 0/2 [05:56<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-03-24 21:18:22,278]\u001b[0m Trial 0 failed with parameters: {'arch.attn_dropout': 0.0, 'arch.dropout': 0.2, 'arch.d_model': 480, 'arch.n_layers': 3, 'arch.n_heads': 6, 'arch.d_ff': 320, 'init_weights': True} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/pip-global/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_15494/3333125453.py\", line 28, in objective\n",
      "    pm.execute_notebook(\n",
      "  File \"/usr/local/pip-global/papermill/execute.py\", line 113, in execute_notebook\n",
      "    nb = papermill_engines.execute_notebook_with_engine(\n",
      "  File \"/usr/local/pip-global/papermill/engines.py\", line 49, in execute_notebook_with_engine\n",
      "    return self.get_engine(engine_name).execute_notebook(nb, kernel_name, **kwargs)\n",
      "  File \"/usr/local/pip-global/papermill/engines.py\", line 367, in execute_notebook\n",
      "    cls.execute_managed_notebook(nb_man, kernel_name, log_output=log_output, **kwargs)\n",
      "  File \"/usr/local/pip-global/papermill/engines.py\", line 436, in execute_managed_notebook\n",
      "    return PapermillNotebookClient(nb_man, **final_kwargs).execute()\n",
      "  File \"/usr/local/pip-global/papermill/clientwrap.py\", line 45, in execute\n",
      "    self.papermill_execute_cells()\n",
      "  File \"/usr/local/pip-global/papermill/clientwrap.py\", line 72, in papermill_execute_cells\n",
      "    self.execute_cell(cell, index)\n",
      "  File \"/usr/local/pip-global/jupyter_core/utils/__init__.py\", line 158, in wrapped\n",
      "    return _runner_map[name].run(inner)\n",
      "  File \"/usr/local/pip-global/jupyter_core/utils/__init__.py\", line 125, in run\n",
      "    return fut.result(None)\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/_base.py\", line 441, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"/usr/local/lib/python3.9/threading.py\", line 312, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-03-24 21:18:22,284]\u001b[0m Trial 0 failed with value None.\u001b[0m\n",
      "\n",
      "Optuna study saved to tmp/general.pkl\n",
      "To reload the study run: study = joblib.load('tmp/general.pkl')\n",
      "\n",
      "Study statistics    : \n",
      "  Study name        : general\n",
      "  # finished trials : 1\n",
      "  # pruned trials   : 0\n",
      "  # complete trials : 0\n",
      "\n",
      "Best trial          :\n",
      "\n",
      "No finished trials yet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "obj = create_objective(config.train_nb, search_space, extra_params=extra_params)\n",
    "study = run_optuna_study(obj, study_type='bayesian', direction='minimize', path='./tmp',\n",
    "                 study_name=config.study_name, n_trials=config.n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
