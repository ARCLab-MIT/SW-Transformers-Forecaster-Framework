{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp losses\n",
    "\n",
    "#|export\n",
    "from abc import ABC, abstractmethod\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tsai.basics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Loss(nn.Module, ABC):\n",
    "    def __init__(self, reduction:str=None):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def _reduce(self, loss: torch.Tensor) -> torch.Tensor:\n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        if self.reduction == 'sum': return loss.sum()\n",
    "        return loss\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _compute_loss(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        return NotImplementedError\n",
    "    \n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        loss = self._compute_loss(input, target)\n",
    "        return self._reduce(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MSELoss(Loss):\n",
    "    def __init__(self, reduction:str=None):\n",
    "        super().__init__(reduction)\n",
    "\n",
    "    def _compute_loss(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        return (target-input)**2\n",
    "\n",
    "class MAELoss(Loss):\n",
    "    def __init__(self, reduction:str=None):\n",
    "        super().__init__(reduction)\n",
    "\n",
    "    def _compute_loss(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.abs(target-input)\n",
    "    \n",
    "class MSLELoss(Loss):\n",
    "    def __init__(self, reduction:str=None):\n",
    "        super().__init__(reduction)\n",
    "\n",
    "    def _compute_loss(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        return (torch.log1p(input) - torch.log1p(target))**2\n",
    "    \n",
    "class HubberLoss(Loss):\n",
    "    def __init__(self, reduction:str=None, delta:float=1.):\n",
    "        super().__init__(reduction)\n",
    "        self.delta = delta\n",
    "\n",
    "    def _compute_loss(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        error = target - input\n",
    "        \n",
    "        is_small_error = error < self.delta\n",
    "        small_error_loss = (0.5 * (error ** 2))\n",
    "        large_error_loss = (self.delta * (torch.abs(error) - 0.5 * self.delta))\n",
    "\n",
    "        return torch.where(is_small_error, small_error_loss, large_error_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class WeightedLoss(nn.Module, ABC):\n",
    "    def __init__(self, thresholds:dict, weights:dict):\n",
    "        super().__init__()\n",
    "\n",
    "        # Activity levels' weights can be equal across all variables or different,\n",
    "        # and this should be taken into account during preprocessing. \n",
    "        self.all_variables_have_same_weights = len(weights.keys()) == 1\n",
    "        ranges, weights = self._preprocess_data(thresholds, weights)\n",
    "\n",
    "        self.register_buffer('ranges', torch.Tensor(ranges))\n",
    "        self.register_buffer('weights', torch.Tensor(weights))\n",
    "\n",
    "    def weighted_loss_tensor(self, target: torch.Tensor) -> torch.Tensor:        \n",
    "        batch, variables, horizon = target.shape  # Example shape (32, 4, 6)\n",
    "        variable, max_range, interval = self.ranges.shape  # Example shape (4, 4, 2)\n",
    "\n",
    "        target_shaped = torch.reshape(target, (batch, variables, 1, horizon))  # Example shape (32, 4, 6) -> (32, 4, 1, 6)\n",
    "        ranges_shaped = torch.reshape(self.ranges, (variable, max_range, 1, interval))  # Example shape (4, 4, 2) -> (4, 4, 1, 2)\n",
    "\n",
    "        weights_tensor = ((ranges_shaped[..., 0] <= target_shaped) & (target_shaped <= ranges_shaped[..., 1])).float()\n",
    "             \n",
    "        if self.all_variables_have_same_weights:\n",
    "            equation = 'r,bvrh->bvh'\n",
    "        else:\n",
    "            equation = 'vr,bvrh->bvh'\n",
    "\n",
    "        return torch.einsum(equation, self.weights, weights_tensor)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def loss_measure(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return NotImplementedError\n",
    "    \n",
    "    def _preprocess_data(self, thresholds, weights):\n",
    "        # If each variable has its own weights, calculate the maximum size of weights.\n",
    "        # Padding shorter weights with NaNs prevents heterogeneous tensor errors.\n",
    "        if (self.all_variables_have_same_weights):\n",
    "            ranges = np.array(list(thresholds.values())[:])\n",
    "            weights = np.array(next(iter(weights.values())))\n",
    "        else:\n",
    "            def add_padding(x, padding_value, shape):\n",
    "                result = np.full(shape, padding_value)\n",
    "                for i, r in enumerate(x):\n",
    "                    result[i, :len(r)] = r\n",
    "                return result\n",
    "            \n",
    "            max_size = max([len(array) for array in thresholds.values()])\n",
    "\n",
    "            ranges_raw = thresholds.values()\n",
    "            ranges = add_padding(ranges_raw, np.nan, (len(ranges_raw), max_size, 2))\n",
    "\n",
    "            weights_raw = [weights[key] for key in thresholds.keys()]\n",
    "            weights = add_padding(weights_raw, 0.0, (len(weights_raw), max_size))\n",
    "\n",
    "        return ranges, weights\n",
    "    \n",
    "    def forward(self, y_pred, y_true, reduction='mean'):\n",
    "        error = self.loss_measure(y_pred, y_true)\n",
    "        weights = self.weighted_loss_tensor(y_true)\n",
    "\n",
    "        if reduction == 'mean':\n",
    "            loss = (error * weights).mean()\n",
    "        elif reduction == 'sum':\n",
    "            loss = (error * weights).sum()\n",
    "        else: \n",
    "            loss = error*weights\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "device = 'cpu'\n",
    "ranges = {'A': np.array([[0, 1], [1, 2], [2, 3], [3, 4]]),\n",
    "          'B': np.array([[0, 1], [1, 2], [2, 3], [3, 4]]),\n",
    "          'C': np.array([[0, 1], [1, 2], [2, 3], [3, 4]]),\n",
    "          'D': np.array([[0, 1], [1, 2], [2, 3], [3, 4]])}\n",
    "\n",
    "weights = {'A': np.array([1, 2, 3, 4])}\n",
    "\n",
    "target = torch.tensor([[[0.5, 1.5, 2.5, 3.5, 4.5, 5.5],\n",
    "                        [0.5, 1.5, 2.5, 3.5, 4.5, 5.5],\n",
    "                        [0.5, 1.5, 2.5, 3.5, 4.5, 5.5],\n",
    "                        [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]]], device=device, dtype=torch.float32)\n",
    "\n",
    "input = target + 1\n",
    "\n",
    "expected_weights = torch.tensor([[[1, 2, 3, 4, 0, 0],\n",
    "                                 [1, 2, 3, 4, 0, 0],\n",
    "                                 [1, 2, 3, 4, 0, 0],\n",
    "                                 [1, 2, 3, 4, 0, 0]]], device=device, dtype=torch.float32)\n",
    "\n",
    "solact_levels = ['low', 'moderate', 'elevated', 'high']\n",
    "\n",
    "class DummyLoss(WeightedLoss):\n",
    "        def loss_measure(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "            pass\n",
    "\n",
    "def test_LossWeightsTensor():\n",
    "    loss = DummyLoss(ranges, weights).to(device)\n",
    "    result = loss.weighted_loss_tensor(target)\n",
    "\n",
    "    assert torch.equal(result, expected_weights), f\"Expected {expected_weights}, but got {result}\"\n",
    "    print(f\"Loss Tensor test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "thresholds_ne = {\n",
    "    'var1': [[0, 1], [1, 2], [2, 3]],\n",
    "    'var2': [[4, 5], [5, 6]],\n",
    "}\n",
    "\n",
    "weights_ne = {\n",
    "    'var1': [1, 2, 3],\n",
    "    'var2': [3, 4],\n",
    "}\n",
    "\n",
    "target_ne = torch.tensor([[[0.5,0.5,0.5,1.5],\n",
    "                         [4.5,4.5,5.5,4.5]]])\n",
    "\n",
    "expected_weights_ne = torch.tensor([[[1,1,1,2],\n",
    "                                   [3,3, 4, 3]]])\n",
    "\n",
    "def test_LossWeightsTensor_different_weights():\n",
    "    model = DummyLoss(thresholds_ne, weights_ne)\n",
    "    loss_tensor = model.weighted_loss_tensor(target_ne)\n",
    "    assert torch.equal(loss_tensor, expected_weights_ne), f\"Expected {expected_weights}, but got {loss_tensor}\"\n",
    "    print(\"Test for different weights per variable passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class wMSELoss(WeightedLoss):\n",
    "    def __init__(self, thresholds, weights):\n",
    "        super().__init__(thresholds, weights)\n",
    "\n",
    "    \n",
    "    def loss_measure(self, input, target):\n",
    "        return MSELoss()(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class wMAELoss(WeightedLoss):\n",
    "    def __init__(self, thresholds, weights):\n",
    "        super().__init__(thresholds, weights)\n",
    "\n",
    "    def loss_measure(self, input, target):\n",
    "        return MAELoss()(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class wMSLELoss(WeightedLoss):\n",
    "    def __init__(self, thresholds, weights):\n",
    "        super().__init__(thresholds, weights)\n",
    "    \n",
    "    def loss_measure(self, input, target):\n",
    "        return MSLELoss()(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class wHubberLoss(WeightedLoss):\n",
    "    def __init__(self, thresholds, weights, delta=2.0):\n",
    "        super().__init__(thresholds, weights)\n",
    "        self.delta = delta\n",
    "    \n",
    "    def loss_measure(self, y_pred, y_true):\n",
    "        return HubberLoss(self.delta)(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class ClassificationLoss(WeightedLoss):\n",
    "    def __init__(self, thresholds, loss):\n",
    "        n_variables = len(thresholds.keys())\n",
    "        weights = {'All': np.arange(n_variables)}\n",
    "\n",
    "        super().__init__(ranges, weights)\n",
    "\n",
    "        self.loss = loss\n",
    "    \n",
    "    def loss_measure(self, input, target):\n",
    "        return self.loss(input, target)\n",
    "\n",
    "    def forward(self, input, target, reduction='mean'):\n",
    "        error = self.loss_measure(input, target)\n",
    "        weights = 1 + torch.abs(self.weighted_loss_tensor(target) - self.weighted_loss_tensor(input))\n",
    "\n",
    "        if (error.shape != weights.shape): # To avoid the use of other loss functions as CrossEntropyLoss\n",
    "            weights = weights.mean(dim=1)\n",
    "            \n",
    "        if reduction == 'mean':\n",
    "            loss = (error * weights).mean()\n",
    "        elif reduction == 'sum':\n",
    "            loss = (error * weights).sum()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TrendedLoss(nn.Module):\n",
    "    def __init__(self, loss: Loss):\n",
    "        super().__init__()\n",
    "        self.loss = loss\n",
    "\n",
    "    @staticmethod\n",
    "    def _slope(y):\n",
    "        x = np.arange(len(y))\n",
    "        slope, _ = np.polyfit(x, y, deg=1)\n",
    "        return slope\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_trends(tensor):\n",
    "        np_tensor = tensor.cpu().detach().numpy()\n",
    "        trends = np.apply_along_axis(TrendedLoss._slope, 2, np_tensor)\n",
    "        return torch.Tensor(trends)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        batch, variables, _ = input.shape\n",
    "\n",
    "        input_trend = TrendedLoss._calculate_trends(input)\n",
    "        target_trend = TrendedLoss._calculate_trends(target)\n",
    "        \n",
    "        trend_diff = 1 + torch.abs(input_trend - target_trend)\n",
    "\n",
    "        error = self.loss(input, target)\n",
    "        weights = trend_diff.reshape(batch,variables,1)\n",
    "        loss = (error * weights).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "def check_loss_function(loss_class, expected_value, loss_func=None):\n",
    "    if loss_class.__name__ == \"ClassificationLoss\":\n",
    "        loss = loss_class(ranges, loss_func).to(device)\n",
    "    elif loss_class.__name__ == \"TrendedLoss\":\n",
    "        loss = loss_class(loss_func).to(device)\n",
    "    else:\n",
    "        loss = loss_class(ranges, weights).to(device)\n",
    "    \n",
    "    result = loss(input, target)\n",
    "\n",
    "    assert torch.isclose(result, expected_value), f\"Expected {expected_value}, but got {result}\"\n",
    "    print(f\"{type(loss).__name__} test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "def test_wMSELoss():\n",
    "    expected_mse_loss = torch.mean(expected_weights * (target - input) ** 2)\n",
    "    check_loss_function(wMSELoss, expected_mse_loss)\n",
    "\n",
    "def test_wMAELoss():\n",
    "    expected_mae_loss = torch.mean(expected_weights * torch.abs(target - input))\n",
    "    check_loss_function(wMAELoss, expected_mae_loss)\n",
    "\n",
    "def test_wMSLELoss():\n",
    "    expected_msle_loss = torch.mean(expected_weights * ((torch.log1p(target) - torch.log1p(input)) ** 2))\n",
    "    check_loss_function(wMSLELoss, expected_msle_loss)\n",
    "\n",
    "def test_wHuberLoss():\n",
    "    delta = 1\n",
    "    expected_hubber_loss = torch.mean(expected_weights * \n",
    "                                   torch.where(torch.abs(input - target) < delta, \n",
    "                                                0.5 * (input - target) ** 2,\n",
    "                                                delta * (torch.abs(input - target) - 0.5 * delta)\n",
    "                                                )\n",
    "                                  )\n",
    "    check_loss_function(wHubberLoss, expected_hubber_loss)\n",
    "\n",
    "\n",
    "\n",
    "def test_ClassificationLoss():\n",
    "    expected_classification_loss = MSELoss('mean')(input, target)\n",
    "    check_loss_function(ClassificationLoss, expected_classification_loss, loss_func=MSELoss())\n",
    "\n",
    "def test_TrendedLoss():\n",
    "    expected_loss = torch.mean((target - input) ** 2) # The trend will be the same so the weights will be all 1\n",
    "    check_loss_function(TrendedLoss, expected_loss, loss_func=MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class LossMetrics:\n",
    "    def __init__(self, loss_func, solact_levels):\n",
    "        self.loss_func = loss_func\n",
    "        self.solact_levels = solact_levels\n",
    "\n",
    "    # Weighted Regressive Loss Metrics\n",
    "    def _apply_weighted_loss_by_level(self, input, target, weight_idx):\n",
    "        loss_copy = deepcopy(self.loss_func)\n",
    "        \n",
    "        for idx in range(len(loss_copy.weights)):\n",
    "            if idx != weight_idx:\n",
    "                loss_copy.weights[idx] = 0\n",
    "        \n",
    "        return loss_copy(input, target)\n",
    "    \n",
    "    \n",
    "    # Classification Loss Metrics\n",
    "    def _compute_misclassifications(self, predictions, targets):\n",
    "        classifier = self.loss_func.weighted_loss_tensor\n",
    "        true_labels = classifier(targets)\n",
    "        predicted_labels = classifier(predictions)\n",
    "\n",
    "        misclassified_labels = (true_labels != predicted_labels).int() * predicted_labels\n",
    "\n",
    "        return misclassified_labels.unique(return_counts=True)\n",
    "\n",
    "    def _count_misclassifications_by_level(self, predictions, targets, level):\n",
    "        unique_labels, label_counts = self._compute_misclassifications(predictions, targets)\n",
    "        label_count_dict = dict(zip(unique_labels.tolist(), label_counts.tolist()))\n",
    "\n",
    "        return label_count_dict.get(level, 0)\n",
    "    \n",
    "\n",
    "    # Metrics functions\n",
    "    def loss_low(self, input, target):\n",
    "        return self._apply_weighted_loss_by_level(input, target, 0)\n",
    "    \n",
    "    def loss_moderate(self, input, target):\n",
    "        return self._apply_weighted_loss_by_level(input, target, 1)\n",
    "    \n",
    "    def loss_elevated(self, input, target):\n",
    "        return self._apply_weighted_loss_by_level(input, target, 2)\n",
    "    \n",
    "    def loss_high(self, input, target):\n",
    "        return self._apply_weighted_loss_by_level(input, target, 3)\n",
    "    \n",
    "    def missclassifications_low(self, predictions, targets):\n",
    "        return self._count_misclassifications_by_level(predictions, targets, 1)\n",
    "    \n",
    "    def missclassifications_moderate(self, predictions, targets):\n",
    "        return self._count_misclassifications_by_level(predictions, targets, 2)\n",
    "    \n",
    "    def missclassifications_elevated(self, predictions, targets):\n",
    "        return self._count_misclassifications_by_level(predictions, targets, 3)\n",
    "    \n",
    "    def missclassifications_high(self, predictions, targets):\n",
    "        return self._count_misclassifications_by_level(predictions, targets, 4)\n",
    "    \n",
    "\n",
    "    # Metrics retrieval\n",
    "    def get_metrics(self):\n",
    "        if not isinstance(self.solact_levels, list):\n",
    "            def Metrics_Not_Available(input, target): return '_' \n",
    "            return [Metrics_Not_Available]\n",
    "        elif isinstance(self.loss_func, ClassificationLoss):\n",
    "            return [self.missclassifications_low, self.missclassifications_moderate, self.missclassifications_elevated, self.missclassifications_high]\n",
    "        \n",
    "        elif isinstance(self.loss_func, WeightedLoss):\n",
    "            return [self.loss_low, self.loss_moderate, self.loss_elevated, self.loss_high]\n",
    "        \n",
    "        else:\n",
    "            return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test_LossMetrics():\n",
    "    loss = wMAELoss(ranges, weights).to(device)\n",
    "    metrics = LossMetrics(loss, solact_levels).get_metrics()\n",
    "\n",
    "    loss_value = loss(input, target)\n",
    "    metrics_values = [metric(input, target) for metric in metrics]\n",
    "\n",
    "    assert torch.isclose(loss_value, sum(metrics_values)), f\"Expected {loss_value}, but got {sum(metrics_values)} ({metrics_values})\"\n",
    "    print(\"LossMetrics test passed!\")\n",
    "\n",
    "def test_LossMetrics_for_classification():\n",
    "    loss = ClassificationLoss(ranges, MSELoss()).to(device)\n",
    "    metrics = LossMetrics(loss, solact_levels).get_metrics()\n",
    "\n",
    "    total_counts = 0\n",
    "    for i in range(1, 5):\n",
    "        total_counts += LossMetrics(loss, solact_levels)._count_misclassifications_by_level(input, target, i) \n",
    "\n",
    "    metrics_values = [metric(input, target) for metric in metrics]\n",
    "\n",
    "    assert np.isclose(total_counts, sum(metrics_values)), f\"Expected {total_counts}, but got {sum(metrics_values)} ({metrics_values})\"\n",
    "    print(\"LossMetrics for classification loss test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Tensor test passed!\n",
      "Test for different weights per variable passed!\n",
      "wMSELoss test passed!\n",
      "wMAELoss test passed!\n",
      "wMSLELoss test passed!\n",
      "wHubberLoss test passed!\n",
      "LossMetrics test passed!\n",
      "LossMetrics for classification loss test passed!\n",
      "ClassificationLoss test passed!\n",
      "TrendedLoss test passed!\n"
     ]
    }
   ],
   "source": [
    "#| Test\n",
    "test_LossWeightsTensor()\n",
    "test_LossWeightsTensor_different_weights()\n",
    "test_wMSELoss()\n",
    "test_wMAELoss()\n",
    "test_wMSLELoss()\n",
    "test_wHuberLoss()\n",
    "test_LossMetrics()\n",
    "test_LossMetrics_for_classification()\n",
    "\n",
    "input -= 1 # To make it equal to target and has no effect on the loss\n",
    "test_ClassificationLoss()\n",
    "test_TrendedLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "#|hide\n",
    "from nbdev import *\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
