{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastcore.all import *\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tsai.utils import yaml2dict\n",
    "from tsai.data.external import download_data\n",
    "from collections import Counter\n",
    "from itertools import combinations, chain\n",
    "from tqdm import tqdm\n",
    "\n",
    "config = yaml2dict('../dev_nbs/config/solfsmy.yaml', attrdict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_forecast_2(X_true, y_true, y_pred, dtms=None, sel_vars=None, idx=None, figsize=(8, 4), n_samples=1):\n",
    "    #TODO: add support for dynamic x axis interval in set_major_locator\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "\n",
    "    def _plot_forecast(X_true, y_true, y_pred, sel_var=None, idx=None, figsize=(8, 4)):\n",
    "        if idx is None:\n",
    "            idx = np.random.randint(0, len(X_true))\n",
    "        if sel_var is None:\n",
    "            title = f'sample: {idx}'\n",
    "        else:\n",
    "            title = f'sample: {idx} sel_var: {sel_var}'\n",
    "        if sel_var is None: sel_var = slice(None)\n",
    "\n",
    "        pred = np.concatenate([X_true[idx, sel_var], y_true[idx, sel_var]], -1)\n",
    "        pred[..., :X_true.shape[-1]] = np.nan\n",
    "\n",
    "        true = np.concatenate([X_true[idx, sel_var], y_pred[idx, sel_var]], -1)\n",
    "        true_hist = true.copy()\n",
    "        true_fut = true.copy()\n",
    "\n",
    "        true_hist[..., X_true.shape[-1]:] = np.nan\n",
    "        true_fut[..., :X_true.shape[-1]] = np.nan\n",
    "                \n",
    "        plt.figure(figsize=figsize)\n",
    "        if dtms is not None:\n",
    "            #dtms_plot = pd.to_datetime(dtms[idx])\n",
    "            dtms_plot = mdates.date2num(dtms[idx])\n",
    "            plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "            plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=10))\n",
    "            plt.xlim(min(dtms_plot), max(dtms_plot))\n",
    "            plt.plot(dtms_plot, pred.T, color='orange', lw=1, linestyle='--')\n",
    "            plt.plot(dtms_plot, true_hist.T, color='purple', lw=1)\n",
    "            plt.plot(dtms_plot, true_fut.T, color='purple', lw=1, linestyle='--')\n",
    "            plt.axvline(dtms_plot[X_true.shape[-1]-1], color='gray', lw=.5, linestyle='--')\n",
    "        else:\n",
    "            plt.xlim(0, X_true.shape[-1] + y_true.shape[-1])\n",
    "            plt.plot(pred.T, color='orange', lw=1, linestyle='--')\n",
    "            plt.plot(true_hist.T, color='purple', lw=1)\n",
    "            plt.plot(true_fut.T, color='purple', lw=1, linestyle='--')\n",
    "            plt.axvline(X_true.shape[-1] - 1, color='gray', lw=.5, linestyle='--')\n",
    "\n",
    "        plt.title(title)\n",
    "        pred_patch = mpatches.Patch(color='orange', label='pred')\n",
    "        true_patch = mpatches.Patch(color='purple', label='true')\n",
    "        plt.legend(handles=[true_patch, pred_patch], loc='best')\n",
    "        plt.show()\n",
    "      \n",
    "    assert X_true.shape[:-1] == y_true.shape[:-1] == y_pred.shape[:-1]\n",
    "    assert y_true.shape[-1] == y_pred.shape[-1]\n",
    "    \n",
    "    if idx is not None:\n",
    "        idx = listify(idx)\n",
    "        n_samples = len(idx)\n",
    "        iterator = idx\n",
    "    else:\n",
    "        iterator = random_randint(len(X_true), size=n_samples)\n",
    "    \n",
    "    if sel_vars is None:\n",
    "        for idx in iterator:\n",
    "            _plot_forecast(X_true, y_true, y_pred, sel_var=None, idx=idx, figsize=figsize)\n",
    "    else:\n",
    "        for idx in iterator:\n",
    "            if sel_vars is True:\n",
    "                sel_vars = np.arange(y_true.shape[1])\n",
    "            else:\n",
    "                sel_vars = listify(sel_vars)\n",
    "            for sel_var in sel_vars:\n",
    "                _plot_forecast(X_true, y_true, y_pred, sel_var=sel_var, idx=idx, figsize=figsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "n_samples = 100\n",
    "n_vars = 10\n",
    "lookback = 5\n",
    "horizon = 5\n",
    "X_true = np.random.randn(n_samples, n_vars, lookback)\n",
    "y_true = np.random.randn(n_samples, n_vars, horizon)\n",
    "y_pred = np.random.randn(n_samples, n_vars, horizon)\n",
    "# dtms must be a 2D numpy array of datetime objects with the shape \n",
    "# (n_samples x (lookback + horizon))\n",
    "dtms = np.array([pd.date_range('2020-01-01', \n",
    "                               periods=lookback + horizon, \n",
    "                               freq='D') for i in range(n_samples)])\n",
    "plot_forecast_2(X_true, y_true, y_pred, dtms=dtms, sel_vars=0, idx=0, \n",
    "                figsize=(8, 4), n_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def plot_solar_algorithm_performance(df, var, figsize=(10, 10), ylims_mean=None, \n",
    "                                     ylims_std=None):\n",
    "    # Plot a grid where each row is a solar activity level, and each column\n",
    "    # is a error type (sfu or percent). Each cell is the result of calling the \n",
    "    # function plot_fe.\n",
    "    # Input:\n",
    "    # df: dataframe with the results of the forecasting experiment, with the columns\n",
    "    #     variable, condition, horizon, mean_sfu, std_sfu, mean_percent, std_percent\n",
    "    # var: variable to plot (F10, S10, M10, Y10)\n",
    "    # figsize: figure size\n",
    "    # ylims_mean: List with the y limits of the mean for each error type: \n",
    "    #   [(percent[0], percent[1]), (sfu[0], sfu[1])]\n",
    "    # ylims_std: List with the y limits of the standard deviation for each error type:\n",
    "    #   [(percent[0], percent[1]), (sfu[0], sfu[1])]\n",
    "    # Output:\n",
    "    # None, but it plots the grid\n",
    "    sals = ['low', 'moderate', 'elevated', 'high']\n",
    "    fig, axs = plt.subplots(len(sals), 2, figsize=figsize)\n",
    "    fig.suptitle(f\"Forecast error for {var}\")\n",
    "    for sal_idx, sal in enumerate(sals):\n",
    "        for idx, err_type in enumerate(['percent', 'sfu']):\n",
    "            df_var = df[(df['variable'] == var) & (df['condition'] == sal)]\n",
    "            # Minimum and maximum values across column\n",
    "            min_val_mean = df[f'mean_{err_type}'].min() if ylims_mean is None else ylims_mean[idx][0]\n",
    "            max_val_mean = df[f'mean_{err_type}'].max() if ylims_mean is None else ylims_mean[idx][1]\n",
    "            min_val_std = df[f'std_{err_type}'].min() if ylims_std is None else ylims_std[idx][0]\n",
    "            max_val_std = df[f'std_{err_type}'].max() if ylims_std is None else ylims_std[idx][1]\n",
    "\n",
    "            mean_fe = df_var[f'mean_{err_type}'].values\n",
    "            std_fe = df_var[f'std_{err_type}'].values\n",
    "            ax = axs[sal_idx, idx]\n",
    "            ax.plot(mean_fe, color='#000000')\n",
    "            ax.set_xlabel('Days from Epoch')\n",
    "            ax.set_ylabel(f'Mean [{err_type}]', color='#000000')\n",
    "            ax.tick_params(axis='y', labelcolor='#000000')\n",
    "            ax.set_xticks(range(len(mean_fe)))\n",
    "            ax.set_xticklabels(range(1, len(mean_fe)+1))\n",
    "            ax.set_ylim(min_val_mean, max_val_mean)\n",
    "            ax2 = ax.twinx()\n",
    "            ax2.plot(std_fe, color='tab:red')\n",
    "            ax2.set_ylabel(f'STD [{err_type}]', color='tab:red')\n",
    "            ax2.set_ylim(min_val_std, max_val_std)\n",
    "            ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "            # ax2.set_xticks(range(len(std_fe)))\n",
    "            # ax2.set_xticklabels(range(1, len(std_fe)+1))\n",
    "            n_samples = df_var['n_samples'].values[0] \n",
    "            ax.set_title(f'{sal}\\n{n_samples} forecasts')\n",
    "            # Draw a grid in the background\n",
    "            ax.grid(True, which='both', axis='both', color='lightgrey',\n",
    "                    linestyle='-', linewidth=0.5)\n",
    "            fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "df = pd.DataFrame({'variable': ['F10', 'F10', 'F10', 'F10', 'S10', 'S10', 'S10', 'S10'],\n",
    "                   'condition': ['low', 'moderate', 'elevated', 'high', 'low', 'moderate', 'elevated', 'high'],\n",
    "                   'horizon': [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                   'n_samples': [100, 100, 100, 100, 100, 100, 100, 100],\n",
    "                   'mean_percent': [10, 20, 30, 40, 10, 20, 30, 40],\n",
    "                   'std_percent': [1, 2, 3, 4, 1, 2, 3, 4],\n",
    "                   'mean_sfu': [100, 200, 300, 400, 100, 200, 300, 400],\n",
    "                   'std_sfu': [10, 20, 30, 40, 10, 20, 30, 40]})\n",
    "plot_solar_algorithm_performance(df, 'F10', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def bold_best(X, X_ref, higher_better=False, bold_ref_too=False, \n",
    "              bold_equal=False, use_abs=False):\n",
    "    \"\"\"\n",
    "        Returns X with the best values in bold, with respect to X_ref, position by\n",
    "        position, i.e., if X[0] is better than X_ref[0] it will be bolded. \n",
    "        Input:\n",
    "            X: 1D numpy array\n",
    "            X_ref: 1D numpy array\n",
    "            higher_better: If True, then the best values are the highest ones\n",
    "            bold_ref_too: If True, best values in X_ref are also in bold.\n",
    "            bold_equal: If bold_equal is True, then the values equal to the \n",
    "            best ones are also bolded\n",
    "            use_abs: If True, then the absolute values are used to compare\n",
    "        Output:\n",
    "            X: 1D numpy array with the best values in bold (or a tuple of two\n",
    "            1D numpy arrays if bold_ref_too is True)\n",
    "    \"\"\"\n",
    "    if use_abs:\n",
    "        X_abs = np.abs(X)\n",
    "        X_ref_abs = np.abs(X_ref)\n",
    "    else:\n",
    "        X_abs = X\n",
    "        X_ref_abs = X_ref\n",
    "    if higher_better:\n",
    "        if bold_equal:\n",
    "            best = np.greater_equal(X_abs, X_ref_abs)\n",
    "        else:\n",
    "            best = np.greater(X_abs, X_ref_abs)\n",
    "    else:\n",
    "        if bold_equal:\n",
    "            best = np.less_equal(X_abs, X_ref_abs)\n",
    "        else:\n",
    "            best = np.less(X_abs, X_ref_abs)\n",
    "    # Make bold\n",
    "    X = np.array([f'\\\\textbf{{{x}}}' if best[i] else f'{x}' for i, x in enumerate(X_abs)])\n",
    "    if bold_ref_too:\n",
    "        X_ref = np.array([f'\\\\textbf{{{x}}}' if not best[i] else f'{x}' for i, x in enumerate(X_ref_abs)])\n",
    "        return X, X_ref\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "X_ref = np.array([5, 4, 3, 2, 1])\n",
    "\n",
    "res = bold_best(X, X_ref, higher_better=True, bold_ref_too=False)\n",
    "test_eq(res, (np.array(['1', '2', '3', '\\\\textbf{4}', '\\\\textbf{5}'])))\n",
    "\n",
    "res = bold_best(X, X_ref, higher_better=True, bold_ref_too=False, bold_equal=True)\n",
    "test_eq(res, (np.array(['1', '2', '\\\\textbf{3}', '\\\\textbf{4}', '\\\\textbf{5}'])))\n",
    "\n",
    "res = bold_best(X, X_ref, higher_better=False, bold_ref_too=False)\n",
    "test_eq(res, (np.array(['\\\\textbf{1}', '\\\\textbf{2}', '3', '4', '5'])))\n",
    "\n",
    "# TODO: Bold 3? \n",
    "res = bold_best(X, X_ref, higher_better=True, bold_ref_too=True)\n",
    "test_eq(res, (np.array(['1', '2', '3', '\\\\textbf{4}', '\\\\textbf{5}']),\n",
    "                np.array(['\\\\textbf{5}', '\\\\textbf{4}', '\\\\textbf{3}', '2', '1'])))\n",
    "\n",
    "# Test use_abs\n",
    "X = np.array([-1, 2, 3, 4, 5])\n",
    "X_ref = np.array([-5, 4, 3, 2, 1])\n",
    "\n",
    "res = bold_best(X, X_ref, higher_better=True, bold_ref_too=False, use_abs=True)\n",
    "test_eq(res, (np.array(['1', '2', '3', '\\\\textbf{4}', '\\\\textbf{5}'])))\n",
    "res = bold_best(X, X_ref, higher_better=True, bold_ref_too=False, use_abs=False)\n",
    "test_eq(res, (np.array(['\\\\textbf{-1}', '2', '3', '\\\\textbf{4}', '\\\\textbf{5}'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def convert_uuids_to_indices():\n",
    "    cuda_visible_devices = os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"\")\n",
    "    uuids = re.findall(r\"\\b[0-9a-fA-F]{8}(?:-[0-9a-fA-F]{4}){3}-[0-9a-fA-F]{12}\\b\", cuda_visible_devices)\n",
    "\n",
    "    if uuids:\n",
    "        indices = [str(i) for i in range(len(uuids))]\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_classified_columns (df: pd.DataFrame, thresholds:dict):\n",
    "    \"\"\"\n",
    "    Creates classified columns based on predefined ranges for specified columns in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with classification classification of each column.\n",
    "\n",
    "    \"\"\"\n",
    "    columns_to_classify = df.columns.intersection(thresholds.keys())\n",
    "    solact_levels = ['low', 'moderate', 'elevated', 'high'] \n",
    "\n",
    "    if columns_to_classify.empty:\n",
    "        return df\n",
    "    else:\n",
    "        df_cat = pd.DataFrame()\n",
    "        for column in columns_to_classify:\n",
    "            # ranges tuples come as strings in the yaml file, so we need to convert them to tuples with eval\n",
    "            bins = pd.IntervalIndex.from_tuples(thresholds[column])\n",
    "            df_cat[f'{column}_Cat'] = np.array(solact_levels)[pd.cut(df[column], bins=bins).cat.codes]\n",
    "        return df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "data = {\n",
    "    'F10': [50, 100, 160, 200],\n",
    "    'S10': [30, 70, 170, 220],\n",
    "    'M10': [60, 100, 150, 170],\n",
    "    'Y10': [50, 90, 150, 170]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "thresholds = {\n",
    "    'F10': [(0,75), (76,150), (151,190), (191, df['F10'].max())],\n",
    "    'S10': [(0,65), (66,150), (151,215), (216, df['S10'].max())],\n",
    "    'M10': [(0,72), (73,144), (145,167), (168, df['M10'].max())],\n",
    "    'Y10': [(0,81), (82,148), (149,165), (166, df['Y10'].max())]\n",
    "}\n",
    "\n",
    "\n",
    "# Expected result\n",
    "expected_data = {\n",
    "    'F10_Cat': ['low', 'moderate', 'elevated', 'high'],\n",
    "    'S10_Cat': ['low', 'moderate', 'elevated', 'high'],\n",
    "    'M10_Cat': ['low', 'moderate', 'elevated', 'high'],\n",
    "    'Y10_Cat': ['low', 'moderate', 'elevated', 'high']\n",
    "}\n",
    "expected_df = pd.DataFrame(expected_data)\n",
    "\n",
    "result_df = get_classified_columns(df, thresholds=thresholds)\n",
    "\n",
    "print(result_df.head())\n",
    "\n",
    "pd.testing.assert_frame_equal(result_df, expected_df)\n",
    "print(\"Test passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def clean_f10_values(value):\n",
    "    try:\n",
    "        # Remove any trailing '+' using regex and convert to float\n",
    "        cleaned_value = re.sub(r'\\+$', '', value)\n",
    "        return float(cleaned_value)\n",
    "    except ValueError:\n",
    "        # If conversion fails, return NaN\n",
    "        return np.nan\n",
    "\n",
    "def get_F10_historical_distribution(thresholds:dict):  \n",
    "  \"\"\"\n",
    "  Calculate the distribution of F10.7 values from historical data.\n",
    "\n",
    "  Returns:\n",
    "  dict: A dictionary containing the normalized value counts of F10.7 values and its categories.\n",
    "  \"\"\"\n",
    "\n",
    "  data = config.data\n",
    "\n",
    "  # From here we will extract the data of F10.7 to check its distribution\n",
    "  fnameF107_historical = data.dataF107_path if data.dataF107_url is None else download_data(data.dataF107_url,\n",
    "                                                                              fname=data.dataF107_path)\n",
    "\n",
    "  # Only two columns in the file: Date and F10.7.\n",
    "  df_F10 = pd.read_csv(\n",
    "            fnameF107_historical, delim_whitespace=True, comment='#', header=None, \n",
    "            names=['Date', 'F10'], \n",
    "            parse_dates=['Date'], \n",
    "            na_values=[\".\", \"+\"], \n",
    "            converters={'F10': clean_f10_values},\n",
    "          )  \n",
    "  df_F10['F10'] = df_F10['F10'].astype(float)\n",
    "\n",
    "  # Data preprocessing \n",
    "  # Remove the first rows with missing values\n",
    "  df_F10 = df_F10[((df_F10['Date'] >= '1947-02-14') & (df_F10['Date'] < '1997-01-01'))]\n",
    "\n",
    "  # Fill the missing values with the average of the previous and next value\n",
    "  df_F10['F10'] = ((df_F10['F10'].fillna(method='ffill')) + df_F10['F10'].fillna(method='bfill'))/2\n",
    "\n",
    "  df_F107_cat = pd.Series(get_classified_columns(df_F10, thresholds)['F10_Cat'])\n",
    "  value = df_F107_cat.value_counts(normalize=True).to_dict()\n",
    "  \n",
    "  return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "get_F10_historical_distribution(thresholds)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def euclidean_distance_dict(X:dict, Y:dict):\n",
    "    return math.sqrt(sum((X.get(d,0) - Y.get(d,0))**2 for d in set(X) | set(Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "# Test case 1: Basic test with non-overlapping keys\n",
    "X1 = {'a': 1, 'b': 2, 'c': 3}\n",
    "Y1 = {'d': 4, 'e': 5, 'f': 6}\n",
    "expected_distance1 = np.sqrt(1**2 + 2**2 + 3**2 + 4**2 + 5**2 + 6**2)\n",
    "assert np.isclose(euclidean_distance_dict(X1, Y1), expected_distance1), f\"Test case 1 failed\"\n",
    "\n",
    "# Test case 2: Basic test with overlapping keys\n",
    "X2 = {'a': 1, 'b': 2, 'c': 3}\n",
    "Y2 = {'a': 1, 'b': 2, 'c': 4}\n",
    "expected_distance2 = np.sqrt(0**2 + 0**2 + 1**2)\n",
    "assert np.isclose(euclidean_distance_dict(X2, Y2), expected_distance2), f\"Test case 2 failed\"\n",
    "\n",
    "# Test case 3: Basic test with some overlapping and some non-overlapping keys\n",
    "X3 = {'a': 1, 'b': 2}\n",
    "Y3 = {'b': 2, 'c': 3}\n",
    "expected_distance3 = np.sqrt(1**2 + 0**2 + 3**2)\n",
    "assert np.isclose(euclidean_distance_dict(X3, Y3), expected_distance3), f\"Test case 3 failed\"\n",
    "\n",
    "# Test case 4: Test with empty dictionaries\n",
    "X4 = {}\n",
    "Y4 = {}\n",
    "expected_distance4 = 0\n",
    "assert np.isclose(euclidean_distance_dict(X4, Y4), expected_distance4), f\"Test case 4 failed\"\n",
    "\n",
    "# Test case 5: Test with one empty dictionary\n",
    "X5 = {'a': 1, 'b': 2}\n",
    "Y5 = {}\n",
    "expected_distance5 = np.sqrt(1**2 + 2**2)\n",
    "assert np.isclose(euclidean_distance_dict(X5, Y5), expected_distance5), f\"Test case 5 failed\"\n",
    "\n",
    "print(\"All test cases passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def find_closest_distribution(df_cat, target_distribution, segment_size, val_size):\n",
    "    \"\"\"\n",
    "    Finds the combination of segments in the categorical data that is closest to the target distribution.\n",
    "\n",
    "    Parameters:\n",
    "    df_cat (pd.Series): A pandas Series containing the categorical data.\n",
    "    target_distribution (dict): The target distribution to compare against, given as a dictionary where keys are categories and values are their target proportions.\n",
    "    segment_size (int): The size of each segment to split the data into.\n",
    "    val_size (float): The proportion of the validation split.\n",
    "\n",
    "    Returns:\n",
    "    best_combination (tuple): The indices of the segments that form the closest combination to the target distribution.\n",
    "    segments (list): The list of segments created from the data.\n",
    "    distribution_found (dict): The distribution of categories in the best combination of segments.\n",
    "    \"\"\"\n",
    "    idxs = list(df_cat.index)\n",
    "    segments = np.array_split(idxs, len(df_cat) // segment_size)\n",
    "\n",
    "    value_counts = [df_cat[segments[i]].value_counts().to_dict() for i in range(len(segments))]\n",
    "\n",
    "    num_segments = int(len(segments)*(val_size))\n",
    "    print(f\"Total number of segments:{ len(segments)}, Number of segments for validation: {num_segments} ({num_segments/len(segments)*100:.2f}%)\")\n",
    "\n",
    "    \n",
    "    best_combination = None\n",
    "    best_distance = np.inf\n",
    "    distribution_found = None\n",
    "    comb = combinations(range(len(value_counts)), num_segments)\n",
    "    for c in tqdm(comb):\n",
    "        values = Counter({})\n",
    "        for i in c:\n",
    "            values = values + Counter(value_counts[i])\n",
    "        total = sum(values.values(), 0.0)\n",
    "        distribution = {k: v / total for k, v in values.items()}\n",
    "        \n",
    "        distance = euclidean_distance_dict(distribution, target_distribution)\n",
    "\n",
    "        if distance < best_distance:\n",
    "            best_distance = distance\n",
    "            best_combination = c\n",
    "            distribution_found = distribution\n",
    "    print(\"The closest group of segments to F10.7 categories has an euclidean distance of\", best_distance)\n",
    "    return best_combination, segments, distribution_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "target_distribution = {'A': 0.25, 'B': 0.25, 'C': 0.25, 'D': 0.25}\n",
    "\n",
    "data = {\n",
    "    'category': ['A', 'B', 'A', 'C', 'D', 'B', 'A', 'C', 'D', 'B', 'A', 'C', 'D', 'B', 'A', 'C', 'D', 'B', 'A', 'C']\n",
    "}\n",
    "df_cat = pd.Series(data['category'])\n",
    "\n",
    "# Function parameters\n",
    "segment_size = 5\n",
    "val_size = 0.4\n",
    "\n",
    "best_combination, segments, distribution_found = find_closest_distribution(df_cat, target_distribution, segment_size, val_size)\n",
    "\n",
    "print(\"Best combination of segments:\", list(best_combination))\n",
    "print(\"Distribution found:\", distribution_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "#|hide\n",
    "from nbdev import *\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
